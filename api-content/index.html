{"posts":[{"title":"质谱文献疑惑","content":" 什么是物质的特异性、非特异性？ 内标法的使用? ","link":"https://monsterju.github.io/post/zhi-pu-wen-xian-yi-huo/"},{"title":"通讯协议","content":"波特率指数据信号对载波的调制速度，它用单位时间内载波调制状态改变次数来表示，单位为波特。 比特率指单位时间内传输的比特数，单位bit/s(bps) 波特率越大，传输速度越快。 5V TTL标准 逻辑1：2.4V~5V 逻辑0：0~0.5V 常MA3232芯片转化为TTL标准 RS-232 标准 串口通讯，全双工，常用于计算机、路由与调制调解器（MODEN，猫）之间的通信。设备分为数据终端设备DTE（计算机、路由）与数据通讯设备DCE（调制调解器）。使用DB9接口（COM口） 物理层 电平标准 逻辑0：+3V~+15V 逻辑1：-15V~-3V 协议层 数据包包括起始位、主题数据、校验位及停止位 波特率 串口异步通信，无时钟信号；需两个都通讯设备约定波特率 通讯的起始和停止位 起始信号由一个逻辑0的数据位表示，停止信号由0.5、1、1.5或2个逻辑1的数据位表示 有效数据( 起始位后紧跟传输的主题数据内容，长度一般约定为5、6、7或8位 数据校验 奇偶校验、1校验、0校验以及无校验 RS-232C UART 串口通信，串行，支持异步单向通信和半双工单线通信；支持局域互连网LIN、智能卡（SmartCard）协议与1rDA(红外线数据协会)SIR ENDEC规范；支持使用DMA 预留一个UART通信接口连接电脑，用于调试程序,在串口调试助手上打印信息 UART模块通过RxD和TxD与外界通信，使用硬件流控还会用到CTS和RTS 引脚： TX： RX： nRTS：Request To Send，n表示低电平有效；UART接收器准备好接收新数据时，置低电平0 nCTS：Clear To Send，n表示低电平有效；发送器在发送下一帧数据之前会检测nCTS引脚，低电平则可发送数据，为高电平则在发送完当前数据帧之后停止发送。 串口标志位 TE --- 发送使能 TXE --- 发送寄存器为空，发送单个字节的时候使用 TC --- 发送完成，发送多个字节数据时使用 TCIE --- 发送完成中断使能 RE --- 接收使能 RDRF --- 读数据寄存器非空 RIE --- 发送完成中断使能 UART数据寄存器LPUART Data Register(DATA)，位于系统总线与移位寄存器之间，包含两个寄存器，一个只用于发送，一个只用于接收。发送时把DATA内容转移到发送移位寄存器，然后把移位寄存器数据每一位发送出去，接收时把接收到的每一位顺序保存到接收移位寄存器内然后才转移到DATA寄存器。 控制寄存器LPUART Control Register（CTRL） ： 发送使能位TE为1时，启动数据发送，发送移位寄存器的数据会在TX引脚输出：TE置1后，发送器开始先发送一个空闲帧（高电平），再往DATA寄存器写入要发送的数据；在写入最后一个数据后，需要等待LPUART状态寄存器(STAT)的TC位为1，表示数据传输完成，如果LPUART控制寄存器(CTRL)的TCIE位置1，将产生中断。 接收使能位RE置1时，接收器在RX线开始搜索起始位，确定起始位后根据RX线电平状态把数据存放在接收移位寄存器内，接收完成后再将数据移到数据寄存器内，状态寄存器(STAT)的RDRF位置1，若控制寄存器(CTRL)的RIE位置1时产生中断。 一个字符帧包括起始位+数据帧+停止位。 空闲状态时保持高电平；起始位是一个位周期的低电平，停止位时一定时间周期(由BAUD寄存器的SBNS位控制)的高电平。 -USART 理解时钟序列： sys_clk：系统时钟 uart_rxd：UART要接收的数据 start_flag：开始标志，检测到数据帧的开始位的下降沿 rx_flag：正在接收标志 clk_cnt：时钟计数 rx_cnt：根据clk_cnt来判断每一位数据接收的起止时钟位置（记满一个bit周期），由系统时钟频率与(/)波特率决定每一个bit占据的时钟数（周期数），对接收到的数据进行位计数标记（对每一个数据位进行计数），判断每一数据帧的接收起止情况。 uart_done：结束标志，检测到数据帧的停止位的上升沿 uart_data：根据rx_cnt的位标记，确定一个数据帧的完整内容，完成串转并、并转串的过程 uart_en：使能端，脉冲，检测上升沿 uart_din：要发送的数据 en_flag: 开始发送标志 tx_flag：正在发送标志 tx_cnt：数据位计数标记 uart_txd：并转串，发送数据 RS-485 终端电阻，典型值为120欧姆，使信号更稳定，消除共模干扰。一般位于差分信号之间 RS485 差分线AB 半双工 逻辑1：+2V~ +6V 逻辑0：-6V~ -2V ","link":"https://monsterju.github.io/post/tong-xun-xie-yi/"},{"title":"质谱仪系统","content":"压力 在质谱仪达到基础压力（低于 2.0 × 10-5 torr = 0.20 V）后，开始测试。1.3 × 10-5 torr比较好 源排气压力开关： 真空 泵管，加长/加粗的真空管路将大大降低抽气效率，造成系统真空度差。 连接越多，漏气的可能越多 拆卸部件的思考：注意对真空的影响 密封圈（O圈）的使用：表面灰尘的清洁？ 卡箍的使用：判断是否正确箍紧？ 泵 通风散热 机械泵 分子泵 泵油： 管道 排气软管和真空软管不能有任何严重弯曲 接地 打开及关闭仪器前的操作 打开： 关闭：先关闭样品流动；去激活，关闭服务进程；排气先后顺序：先分子再机械，真空室需要先排气，避免低真空泵的废弃被吸回； ","link":"https://monsterju.github.io/post/jTebPp1h4/"},{"title":"质量分析器","content":"是利用不同类型的电场和磁场使离子束偏转（偏转聚焦）并将其按质荷比分开的离子光学器件。 （“棱镜与透镜“”的离子光学特性） 质谱仪器中质量分析器常采用均匀或非均匀磁场、圆柱形、球形或环形电容器等静电场或四极场。 （扇形场透镜或四极透镜），利用离子在电磁场中的运动与光线在光学介质中传播之间的相似性进行研究。 真空状态，离子流较小不存在空间电荷效应 场作用力决定离子轨迹 各种离子源的电离过程一般会使所形成的离子获得不完全相同的初始动能；对于同一质荷比的离子来说，由于其初始动能不同，在同一加速电压的作用下，也会以实际不同的动能离开离子源进入分析器。 质谱仪器在实际工作时，为获取不同质荷比离子的质谱图，通常是用连续改变磁场强度的方法来扫描不同质荷比离子的轨迹，从而在出口狭缝处记录相应的离子流，所记录到的离子流分布是呈三角形的。（离子流的浓度强度的变化） 双曲线电极和双曲线磁极 静态磁式质谱仪 电扫描： 改变加速电压U，U与质荷比成线性关系； 改变U值，影响仪器的分辨率和灵敏度：提高，则提高 磁扫描： 改变磁场强度H，且扫描过程中仪器性能（分辨率与灵敏度）能保持不变； 磁滞回线有一定宽度，不能用励磁电流值作为质荷比读数刻度； 磁扫描存在滞后时间，不利于快速测试; H值与质荷比的平方根成正比，H值在该范围内无法做精确精确，因此质荷比测量误差较大； 单聚焦仪器具有方向聚焦的特性，可以将按一定角度范围入射磁场的离子按质量色散得到质谱，但离子源给出的离子束总有一定程度的能量发散，扇形磁场对于质量相同但能量不同的离子也有色散作用，即按质量色散的质谱上还叠加着能量色散；单聚焦仪器不能得到清晰的质谱像 双聚焦仪器通过扇形磁场和电场的串接可进行方向聚焦和能量聚焦：利用扇形电场将离子先按能量色散分开，再用扇形磁场能量色散的逆作用将其抵消（可相互抵消，双聚焦必要条件），实现能量色散；又由于扇形磁场本身具有质量色散特性，以及扇形电场和磁场均具有方向聚焦性质（必需满足），串接后就实现了方向和能量双聚焦； 扇形磁场可以把能量相同的离子按不同质量分开，也可把相同质量的离子按照不同能量分开，且这一过程可逆：可将质量相同并已经按照能量不同分开的离子重新汇合起来； 扇形电场具有能量色散的特性，可将离子按照能量分开，不论质量如何。 四极质谱仪 飞行时间质谱仪 疑惑 找固定一个质量数，但是质谱图出现的峰中，峰宽是一个质量范围，是不是意味着越窄，分辨率越高，或者和扫描线相关？？？ 扫描线是通过改变直流电压U和射频电压V来选择不同质量数，质量数大的对应的稳定区也大，那扫描线的斜率值（宽度增益，width gain）对质量数大的影响更大：斜率低，可能导致峰宽更大； 质谱的峰宽和峰面积由扫描线在稳定区的位置所确定； 截距（宽度补偿，width offset）对整个质量范围的峰宽影响相同； 宽度增益值或宽度补偿值越 大，分辨率越高，峰强度越小。这是因为能够穿越四极杆的离子数目减少了，从而降低了峰强 度和信噪比。 Q3扫描时，为什么要在Q2内充入少量碰撞气CAD，但是Q2没有加碰撞能量（不会出现碰撞离子），来聚焦Q3离子提高信号强度（真空度在2.0左右）？？ 碰撞气怎么起作用的? 灵敏度和分辨率的关系？ 灵敏度和响应强度的关系 8个扫描模式的区别？ Q1、Q2和Q3在不同模式下的状态及作用？ 单个质量范围的扫描？ 全扫描？ 多离子扫描？Multiple ions MRM？ 中性损失？ 前体离子和产物离子扫描的区别？ 前体离子其实也是检测产生的离子，若样品中存在与前体离子相对应的化合物，？？ ","link":"https://monsterju.github.io/post/-4-USDr9N/"},{"title":"analyst与质谱仪操作记录","content":"analyst 质量轴校正 拟合曲线调整：手动和自动； 小技巧：用已校正的数据（Dac）来拟合曲线，来估计未校正的质量轴（线性关系） Dac Dac是数模转换，根据mass值转化为电压的关系吗？ 是的， 实验中那个斜率为107是如何确定的？需要知道是几级？ tool-&gt;settings-&gt;intrument options-&gt;calision table... 粗略调整质量轴 斜率等于MASS（Da）/ Dac 线性关系 参数扫描 Declustering Potential（DP） Entrance Potential（EP） cxp ro2 根据强度条件寻找对应值；？？？ 精细调整质量轴 DP设置电压：不用从0-300V，从0-200V就足够了 更改的是哪一个参数？？？ 一般相同母离子的子离子，DP应一致 寻找目标峰：调整分辨率，通过调整峰宽（Mass）的offset。 分辨率越高，峰分得越开？是的 峰宽度变化 offset的调整：分辨率偏小减小offset，分辨率偏大增加offset；每次微调0.003？ 调整Offset值会影响分辨率，如增加offset值，会增加离子在四极杆中得循环数，离子强度会降低，但峰形更窄、分辨率更好。 默认 峰宽为6Da。质量轴偏，找不到目标峰，强度低，则可以尝试调大峰宽，增加寻找范围。 扫描模式 full-scan 全扫描模式，定义扫描的质量范围的起点终点，一般用于校正仪器和寻找母离子。 single Ion monitoring(SIM),对固定的质量数进行监控；背景噪声较低，信号强度不变，但S/N更高，一般用于定量分析。可能存在假阳性。 Q1/Q3 full-scan Q1/Q3 SIM product ion scanning precursor ion scanning Neutral Loss Scanning ： 中性丢失，P..I..S..模式的补充，用于定性，Q1和Q3 都同时处于SCAN模式，两者总相差固定的质量数（质谱图意味着Q1和Q3 出现了规定差值的离子对），同步扫描。 MRM ： 多反应监控，Q1和Q3都处于SIM模式，可跳跃监控多对离子对；信噪比好，主要用于定量分析。 检测器 CEM检测器范围：2000~3000V，正负离子模式下各自独立，不一定总是需要最高的电压；CEM尝试增加100V，若信号强度提高超过10%，则CEM提高100V，否则不用提高。 Deflector电压可调（±400V），DF电压调好后基本不变 质谱仪 排气步骤 注意液相阀门的开关顺序 注射泵排气，压紧 调谐液 调谐进调谐液的时候，离子源不会加热；流速慢 ","link":"https://monsterju.github.io/post/J70U6hWCi/"},{"title":"前置理论","content":" 质谱仪类型 同位素质谱仪 类似于光学中的摄谱仪，利用感光板来测定离子流强度 双聚焦质谱仪 马陶赫-赫佐格型双聚焦质谱仪 火花离子源质谱仪 离子探针质谱仪 飞行时间质谱仪 色谱-质谱联用仪 质谱仪器的组成、分类、主要参数及应用 组成 进样系统将被分析的物质即样品送进离子源； 离子源将样品中的原子、分子电离成离子； 质量分析器是离子按照质荷比的大小分开； 离子检测器用以测量、记录离子强度而得到质谱仪。 仪器在给定时间内只能记录一种极性的离子。需能迅速切换极性，以用于对快速的瞬态事件做出高保真度的记录。 分类 质量分析器按工作状态可分为静态仪器与动态仪器。 静态是指利用稳定的电磁场，按空间位置来分离离子束； 动态是指或利用纯高频电场，按离子轨迹稳定或不稳定来分离离子束（四极质谱仪），或利用无场漂移空间，按离子飞行时间的快慢来分离离子束（飞行时间质谱仪）。 静态仪器也可按质量分析器对聚焦性能，分为无聚焦、单聚焦、双聚焦。 主要参数性能 质量范围 表示仪器能分析的样品的相对原子质量（或相对分子质量）的范围，通常用原子质量单位来度量。 分辨率R 表征质谱仪器分离相邻质量离子的能力 公式 实际测试： 实际中利用仪器获得的质谱图来衡量分辨率。但在质谱图中，判断两个峰是否分开未有明确的规定，通常认为当两个峰之间的“谷值”低于两个峰高的给定百分数（通常为10%或50%）时，两个峰就分开了。但这种测试方法要求两峰的高度相等，但实际中很难找到等高的相邻峰。 为什么说分辨力高，但是得到的相应低？ 灵敏度 精密度和准确度 理论发展 离子光学理论 软电离方法 包括化学解吸电离法、激光解吸法、场解吸法、二次离子质谱法、快原子轰击法等 射频RF 本质就是电磁辐射EMR。有电压就有电场，有电流就有磁场，变化的电场和磁场产生电磁波。在电路 中，任何变化的电流和电压都会产生电磁辐射，大多数情况下，这些电磁辐射只是产生噪声，对通信系统产生影响时，就是成了电磁干扰EMI。RF设计使生成、操控和解释EMR的科学。 传播速度快，光速；传播距离远；可以穿透墙壁；无处不在； 真空技术 阴极阳极与正极负极 LC/MS中的用气问题 了解质谱由几个部分组成，每个区域要解决什么问题，会发生什么问题，然后每个区域是否会使用到气体？ 质谱常用的气体有喷雾气、脱溶剂气、碰撞气、帘气（反吹气） 首先，在离子源区和离子传输区，为的是把液相流过来的样品离子化，所以这个区域使用的气体就是帮助离子化的，那么选惰性气体最好，由于使用的气体量很大且贵，一般选择氮气。 帮助离子化的辅助气。考虑气体流速影响灵敏度 用于抵抗污染，如AB叫帘气、Thermo叫吹扫气、Agilent叫反吹气。这路气体可以不开，对脏样品有用，但对干净样品会降低灵敏度。 用于加热，来提高离子化效率。Waters、Thermer的大部分仪器都可以加热离子源框架，或者离子传输管，不再加热气体。但AB的Turbo源、Thermo的H-ESI源，都是喷针旁边用氮气流加热。Agilent/Bruker的仪器不对喷针加热，不对离子传输管用电路直接加热，而是再传输管外侧就用热热氮气流加热。加热，气体挥发加快，仪器耗气量增加。 离子源中不一定要用高纯的氮气，可以用普氮，但是气体进入质谱的地方（滤膜等）会脏，需要经常检查清洗、更换。 在真空的分析区，要求使用绝对（高纯）的惰性气体以完成碰撞（碰撞气），否则会出现“鬼峰”？。 优先考虑使用氩气，比氦气便宜（串联四极杆、Q-TOF都是用氩气） 并且，在离子阱设计中，氩气还具有缓释动能的作用，使离子快速稳定在阱的中央，这种气体叫做&quot;damping gas&quot;。 Q3扫描时在Q2中会充入少量的CAD气，由于Q2没有加碰撞能，所以并不会出现碰撞碎片，目的是 为了聚焦Q3离子，提高信号强度，？？ 真空状态的保持 质谱的真空系统由两部分串联构成，前级机械泵和涡轮分子泵。 机械泵的抽真空能力约为0.1-1mTorr， 而分子涡轮泵抽真空能力达到10-9Torr，1Torr=133.32Pa，一个毫米汞柱对应的大气压。 分子泵是涡轮分子泵、牵引分子泵和复合分子泵的统称，有转速限定，用来获得高真空和超高真空；得在稀薄气体分子流状态下才能工作，需要配合合适的前级泵（机械干泵）；理论上可以在大气压下工作，只是转速低，抽气的流量很小；如果高转速在大气压下工作，分子气体在相邻的叶片间弹射，大量气体分子会将分子泵叶片敲打变形。 前级机械泵工作一段时间，真空度稳定后才可开分子涡轮泵；关机时也要先关分子涡轮泵，等分子涡轮泵完全停机之后才可关机械泵电源。 真空度 各个部件的电压 轴向电压 ：在串联的部件中形成梯度电压，如果是正离子进入四极杆，梯度电压应从0V开始越来越来越小，是负离子进入四极杆，梯度电压应该是从0V开始越来越大。 IE，离子能量，对于质量一定的离子，调节IE可以调节离子通过四极杆的速度；提高IE，离子速度增加，分辨率降低，信号强度增加；降低IE，会减慢离子速度，一定程度会增加分辨率，但信号强度降低 FDC，直流电压： RF，射频电压： 分辨率 Resolution 四极杆质谱的半峰宽FWHM恒定，分辨率不固定， 小离子的分辨率较低，而大离子的分辨率高；而高分辨质谱如TOF或磁质谱有恒定的分辨率，离子越小峰越窄，离子越大，峰越宽；？？？ 灵敏度 Sensitivity 在规定条件下，对选定化合物产生的某一质谱峰，仪器对单位样品所产生的响应值。 浓度和相应强度的关系。（可接受的线性范围） 分辨率与灵敏度的调整 加速电压的影响： 前体离子和产物离子 前体离子，也称母离子，是反应形成特定的产物离子的离子，反应可以是单分子解离、离子/分子反应、异构化或电荷状态的变化。 产物离子也称碎片离子或子离子，是参与某特定前体离子反应形成的产物离子，反应可以是单离子解离，形成碎片离子、离子/分子反应、或简单地涉及电荷数的变化。 准分子离子 指质子化和去质子化的分子 比分子量多或少1质量单位的离子，其不含未配对电子，结构上比较稳定。 思路 寻找不同的方法来是样品分子带电形成离子，带电粒子才能通过电磁场来驱动，以此进行加速、控制运动、筛选不同的粒子；其中也有不同控制方法、提纯聚焦方法、筛选方法。考虑密度强度、利用率等。 电晕放电和击穿空气 电晕放电：在导体尖端不均匀电场导致的放电现象。单电极； 击穿空气：在足够高的电场强度下，空气介质被大量电离，导致电极间贯穿性的放电。电子雪崩理论； ","link":"https://monsterju.github.io/post/ve-wYfbyh/"},{"title":"三重四极杆质谱仪","content":"陶瓷镀金的作用 自由度：在物理学中描述一个物理状态，独立对物理状态结果产生影响的变量的数量。 电压的使用 簇离子的处理 簇离子会降低所要检测的被分析物质量处的信号；会增加背景信号，影响方法的重现； 解决： 加热（Interface Heater on） 气帘气的ing用可帮助溶剂挥发，防止簇离子的产生 调节DP电压，但DP过高会引起源内裂解 ESI的离子蒸发 液滴带有两种极性的离子（其中一种占主导），随着溶剂挥发，液滴表面某种极性的离子增多，电场增强； 当电场超过某个阈值后，离子互相排斥就从液滴的表面飞溅出去，而残留物通过废液系统排出去。 检测器 同位素的影响：检测器饱和，导致峰值分辨率和位置不准确，影响评估峰位置和宽度。 ","link":"https://monsterju.github.io/post/9n2vb914a/"},{"title":"常见电离源","content":"##真空状态下使用的电离源： 电子轰击电离源 Electron Impact Ionization，EI 化学电离源 Chemical Ionization，CI 快原子轰击源 Fast Atom Bombardment，FAB 基质辅助激光解析电离 Matrix-Assisted Laser Desorption Ionization，MALDI ##大气压状态下使用的电离源： 电喷雾电离源 ELectrospray Ionization，ESI 大气压化学电离源 Atmospheric Pressure Chemical Ionization，APCI 大气压光电离源 Atmospheric Pressure Photo spray Ionization，APPI 电子轰击电离源 一般用于小分子量的、无机的气体分子物质。 固体、液体样品需要加热气化才进入离子源，则需考虑热稳定性与挥发性。 常与气相色谱联用 电子轰击，发生能量交换，被测物质的分子或原子失去价电子生成正离子，或捕获电子生成负离子。 商用EI源使用的轰击电子的能量一般为70eV，具有较多的标准库；较高的电子能量可使分子离子上的剩余能量大于分子中某些键的键能，而使分子离子发生裂解。 使用较低的电离电压，来控制碎片离子的数量和分子离子峰的强度。 结构上： 加热灯丝（位于阴极）产生电子，在另一端的阳极（在电场作用下？）收集阴极发射的电子和在电离过程中产生的负离子（即电子）。（后面只分析正离子） 灯丝常用钨丝和铼丝，常用两条灯丝；设置屏蔽罩防止阴极按全方位角发射电子，利用罩上一定的电位，使电子以同一方向进入电离室。 阴极对仪器的灵敏度、稳定性和分辨率都有影响，需稳定阴极丝的供电电流，以保证发射电子流的稳定性；即通过全波整流后的直流经晶闸管向钨阴极提供2-5A的直流电流，构成负反馈机制。 在电离室中产生的正离子，由处于负电位的加速电极引出并使之加速。 再使用永久磁铁产生磁场，目的是使电子以螺旋运动的形式通过电离室，以增加电子在电离室中的路径！ 辅助磁场方向大致与电流方向一致，电子绕磁力线做螺旋运动。（电离室产生的正离子也做螺旋线运动） 质量歧视效应：不同质荷比（m/ze）的离子具有不同的运动半径。则不同质荷比的离子具有不同的初始能量，会引起离子能量分散，这会直接影响仪器的分辨率。为减小质量歧视效应，一般会把电离室的宽度做的很小，同时采用推斥极来改善电离室内的电位分布。 离子推斥极，改善电离室内的电位分布，限制电子和离子定向运动，来增大离子流强度，减少离子能量分布。一般取一对，位于电离室的上下方，来构成电子束的宽度的限制尺寸。 离子光学系统，离子源设计的关键，作用是通过静电透镜系统将离子引出电离室，并进一步加速、聚焦成一定形状的离子束；静电透镜是指施加一定电位的中心开孔的金属薄板或圆筒构成的电子和离子光学器件，将电离室中大部分的离子以很小的散角送至质量分析器。 化学电离源 一般用于电离分子量大的、稳定性差的有机物 化学电离是基于离子-分子反应产生离子，即利用大量反应气体的离子与少量样品分子之间的碰撞来生成样品离子，而反应气体的离子是用电子轰击反应气体产生而产生的。 化学电离源的关键是既要维持较高的工作气压，又要不影响电子束的射入和离子束的引出。源附近的气压分布：电离室内压强高，电离室外压强低，将电离室外的碰撞减至最小。使用两套独立的真空系统进行差级抽气，离子源要用高速抽气泵。 需要保持电离室的气密性，即离子引出缝和电子入射口的截面不能过大。 选择不同的反应气体来控制化学电离的碎片离子的种类和数目，产生正离子的机理有： 将过程看成是从一个酸性反应气体离子向样品分子的质子迁移 ·反应气离子捕获（样品分子直接与整个反应气体离子结合 电子迁移 化学电离也可使样品分子电离负离子，电子与样品分子的相互作用产生负离子的机理有： 谐振捕获 离解谐振捕获 离子对得到形成 反应气离子与样品分子作用而形成负离子 负离子质谱 大气压化学电离源 由于结构与极性的限制，APCI可作为ESI的补充，来增加离子产率； 与电喷雾电离源结构大致相同，不同之处在于APC喷嘴的下游放置一个针状放电电极； 通过放电电极的高压放电，使空气中的某些中性分子（N2，O2气体）电离，溶剂分子也会被电离，这些离子与分析物分子发生离子-分子反应，使分析物分子离子化，这些反应包括质子转移和电荷交换产生的正离子，质子脱落和电子捕获产生的负离子等。 存在基质效应； 为什么溶剂分子被电离了，但是样品（分析物）分子没有被电离？ 加热为了雾化、气化？ 火花电离型离子源 利用真空高压放电使样品电极产生电离 前击穿阶段 高压击穿（火花击穿）阶段 电弧阶段 离子轰击型离子源 利用气体放电或其他方式产生的具有一定能量的一次离子束，轰击真空中的固体表面，会发生：一次离子的散射，中性粒子、正负二次离子的溅射，二次电子、X射线和光的发射。 离子束与样品表面（靶面）成一定的入射角 二次离子质谱法：直接引出溅射二次离子进行分析 电离中性粒子质谱法：利用辅助电子束碰撞溅射出来的中性粒子，分析电离后的离子 快原子轰击离子源 适用于极性和不挥发、热不稳定化合物的电离 用一个离子源将输入的氩气电离成为离子，然后将氩离子与中性氩气碰撞，由所发生的谐振电荷迁移过程，获得与氩离子的能量相近的快原子束；再轰击样品，同样是检测二次离子。 激光离子源 激光具有很强的能量，激光器产生的相干光束能会聚成高辐射密度的光束，并聚焦在很小的面积上，可以产生极高的表面温度，激光离子源可用于蒸发和电离样品（不挥发、热不稳定）。 出现以下效应：热电子发射、热离子发射、中性原子/分子蒸发、光电离； 所产生的离子流延续时间短需要快速反应的质量分析器； 场致电离离子源 可用于气态样品的电离，不可用于电离不挥发或热不稳定的化合物；除非是场致解吸 在距离很近的阳极和阴极之间，施加几千伏的稳定直流电压，在阳极的尖端附近产生强电场，可将非常尖端的气态样品分子中的电子拉出去，而形成离子。 隧道效应 产生场致电离的时间短，也需要快速响应的质量分析器和检测系统 场致解吸可以不用加热而形成分子分离，但是所得到的总离子流比其他方法都低 ","link":"https://monsterju.github.io/post/dw-0_CjgS/"},{"title":"质谱数据处理","content":"天大色谱-质谱数据处理会议1 算法需求： 质谱数据 寻峰并确定中心，进行半峰宽计算和质量轴校正 质心法 基线漂移 波峰面积方法：半峰估计全峰、补全完整波 波的形状预判（波缺陷的位置）：求导 输入： 输出：找波，获得起始点、结束点、峰值及对应强度、半峰宽、 小波找拐点： 噪声 波高度、斜度误差，误识别 色谱数据 通过峰高或峰面积估计浓度 （拟合曲线） 标准品的浓度 确定标准曲线 横坐标是什么？时间 纵坐标是强度（intensity） 同一个窗口内有多个峰的问题： rt窗口 异常：尾部有包 分解峰 算法设计，验证完善 ","link":"https://monsterju.github.io/post/R7vIQ5Oa3/"},{"title":"质谱","content":"质谱仪：一台称量分子和分子碎片质量的仪器；化学向 质谱法（MS）是利用电磁学原理，将待测物质离子化，并按照质荷比（m/z）大小对生成的离子进行分离、检测和记录，根据所得到的质谱图进行定性、定量及结构分析的方法。（通过适当的稳定或变化的电磁场将离子按空间位置、时间先后等方式实现质荷比分离） 分析蛋白质和肽这样的大分子，还是水性小分子的数据？ 要在以确定的浓度水平中寻找目标化合物，还是要表征未知样品？ 处理样品的数量? 质谱过程： 样品溶液 ——&gt;气态分子 ——&gt;离子 ——&gt;按质荷比排序 ——&gt;输出信号 包括进样系统、离子源、质量分析器及检测器。后3种装置均需在真空中工作。 质荷比（m/z） 相对原子质量 同位素丰度 C12 1Da等于一个碳12同位素原子质量的1/12 评判 Resolving Power = M/▲M 分辨率 Resolution = 平均M/▲M 工作模式 由易挥发的分子产生离子 -- 电子轰击EI -- 化学电离CI 由难挥发的分子产生离子 -- 快离子轰击FIB -- 电喷雾电离ESI 激光解吸LD --基质辅助激光解吸MALDI 离子分析 磁质谱仪 离子回旋共振(ICR)质谱仪 飞行时间质谱仪TOF 四极杆质谱仪 -离子阱质谱仪 质谱中的离子破碎 分离系统 气相色谱-质谱联用 GC-MS 液相色谱-质谱联用 LC-MS 质谱-质谱联用 MS-MS ","link":"https://monsterju.github.io/post/zhi-pu/"},{"title":"眼电处理遇到的问题","content":"寻找局部最大值 怎么确定时间窗口 在找到每一次epoch的局部最大值时，向前向后延长一段时间寻找峰值（感兴趣的时间范围） 差分值 ","link":"https://monsterju.github.io/post/yan-dian-chu-li-yu-dao-de-wen-ti/"},{"title":"脑电信号处理","content":" 脑电的特征与分析 EEG包括EEG（静息态）和ERP（任务态，事件相关） EEG：频域分析、时频分析、功能连接、微状态 ERP：时域分析、时频分析、溯源分析 预处理 导入数据 不同厂家的脑电设备导出的数据格式是不一样的！ 将不同文件通过EEGLAB保存为.set文件 电极定位，设置channel lacation文件(BESA[正常分析]、MINI[溯源分析]) 剔除无用电极及标签，select data、select epochs or events 滤波 由于50Hz的市电干扰以及一些高频和低频的噪声存在，预处理需要进行滤波处理 ？滤波是直接把采集到的数据中超过一定频率的内容删掉？ -&gt;把脑电信号拆成不同频率的脑电，在去除不需要的频段（区分时域、频域滤波） 低通、高通、带通、带阻 带阻滤波勾选Notch... 降采样 采样率 = 采样点数/单位时间 一个点的采样周期 = 1/采样率 EEGlab界面解释 Frames per epoch：每一段有多少帧，即每一段有多少采样点 Sampling rate：采样率 Epoch start：每一段的开始时间 Epoch end：这一段的结束时间，按时刻点开始计算，即采样点数 = 采样率 * (end-start+1/采样率) 注意采样点与时刻点的区别 为什么要降采样？ Nyquist采样定理：采样率必须在感兴趣的频率2倍以上，最好达到3-4倍，脑电信号的采样率一般在250Hz-1000Hz. 在满足ERP的需求下，减少数据量，加快计算速度 分段和基线校正（ERP） Extract epochs 注意分段的区间限制，预留空间做精细化处理 插值坏导和剔除坏段 Spherical算法：容积传导效应，利用周围电极电位对该电极电位的影响权重不同，重新赋值 Interpolate electrodes -&gt;select from data channels plot -&gt; channel data -&gt;REJECT 重参考 脑电信号采集的信号，就是电极所在位置跟参考电极之间的电位差。一般脑电在脑电记录的时候参考电极有鼻尖(Nz)、头顶中央(Cz)、单侧乳突等位置。 常用参考方式：双侧乳突平均参考或全脑平均参考(电极数量少于32个则不适合) Re-reference the data 剔除伪迹/坏段 常见伪迹： 眨眼VEOG：前端分布、小方块、随机分布、低频能量高、成分排序靠前 眼漂HEOG：前端两侧分布，红蓝相对、长条状，红蓝相对、随机分布、低频能量高、成分排序靠前，但一般排在眨眼后 头动：周围分布、长条状、随机分布、在单个Trail里有非常明显的漂移 工频干扰：分布在地线周围、单个Trail上的分布非常规律、50Hz左右能量最高 心电：呈雨点般散落状 ICLable项目:（ICA去伪迹、伪迹矫正）： ICA（盲源分离算法、独立成分分析)可以找到不同脑电信号源活动以及它们的头皮分布：将原始信号分解，分离的独立成分分为伪迹相关成分和神经活动相关成分（将信号和伪迹（眼电心电肌电等成分）分离），剔除被标记为伪迹的相关成分，并对其他成分进行重新组合 Tools -&gt; Decompose date by ICA -&gt; Classify components by ICLable 64导及以下，如果没有插补过坏电极，那么直接跑； 如果插补了，需要在'extended,1'后加参数，'pca',m-n m为当前数据中的点击数量，n为插补的电极数量 电极数量大于64导系统时，只跑64个成分即可 绝对值法/极端值去伪迹（伪迹剔除） 脑电电压一般在±100uV(更严格，±70uV) 去除成分和坏段的区别： 脑电数据包括信号与噪声，时域分析时可以通过叠加平均提高信噪比（噪声使随机分布的，信号是锁时锁相的）。 绘制ERP波形图和波幅地形图（选定通道，比较随时间变化的波幅，选定时间，比较各通道的波幅 ","link":"https://monsterju.github.io/post/nao-dian-xin-hao-chu-li/"},{"title":"EOG眨眼分类","content":"Here is a basic example for classifying blinks from EOG signals using KNN in Matlab. % Load EOG signal data data = load('eog_signal.mat'); eog = data.eog; % Get n samples before and after each blink for analysis n = 100; % Detect blink locations blinks = find(eog &lt; -500); % Extract n samples before and after each blink blink_feats = zeros(length(blinks), 2*n); for i = 1:length(blinks) feat = eog(blinks(i)-n : blinks(i)+n); blink_feats(i, :) = feat; end % Training labels y = [ones(1,length(blinks)); 2*ones(1,length(blinks))]; % Train test split idx = randperm(2*length(blinks)); train_idx = idx(1:3*length(blinks)/4); test_idx = idx(3*length(blinks)/4+1:end); % Train KNN knn = fitcknn(blink_feats(train_idx,:), y(train_idx),'NumNeighbors',3); % Test predictions preds = predict(knn, blink_feats(test_idx,:)); % Accuracy accuracy = sum(preds == y(test_idx))/length(test_idx) Load the EOG signal data Detect blink locations Extract n samples before and after each blink as features Create labels (1 for before blink, 2 for after blink) Split into train and test Train a KNN model Make predictions on test set and calculate accuracy ","link":"https://monsterju.github.io/post/eog-zha-yan-fen-lei/"},{"title":"研究生调剂记录","content":"每当要认真专注做事情的时候，总有令人感兴趣的意外出现！ 4.6 满怀期待的报考大连大学、汕头大学、海西物构所 4.7 大连大学实验室被拒，广州大学调剂 4.8 十五所、五十四所被拒 4.9 天大、上海师范、西电、电信科研院调剂 4.10 放弃调剂 4.11 天大精仪非全复试通知，8点企业面试 4.13 天津大学学院复试，收到拟录取 最后还是上岸了，非全到底是怎样的一个情况，看来是自己去亲身体会一次了！调剂到电子信息的生物医学工程，这也是一个非常感兴趣的方向。都说生医也是未来方向，真的能遇到风口嘛？ 这几天一直刷到ai的各种模型，这个 世界怎么了？gpt相关的模型好心动啊好厉害啊，发展好快啊！真的可以把ai当成人来看吗？ 希望不后悔吧！ 4.14 对读书能有啥后悔的呢？每一天都是提升自己的时间， 后悔就业吗？ ","link":"https://monsterju.github.io/post/tiaoji/"},{"title":"kurtosis函数与skewness函数 ","content":"matlab的峰值函数与偏度函数在眼电数据处理的应用理解 kurtosis峰值函数 峰度反应的是图像的尖锐程度：峰度越大，表现在图像上面是中心点越尖锐。在相同方差的情况下，中间一大部分的值方差都很小，为了达到和正太分布方差相同的目的，必须有一些值离中心点越远，所以这就是所说的“厚尾”，反应的是异常点增多这一现象。 k = kurtosis(X)返回X的样本峰度。 如果X是一个向量，那么峰度(X)返回一个标量值，该值是X中元素的峰度。 如果X是一个矩阵，那么峰度(X)返回一个行向量，其中包含X中每一列的样本峰度。 如果X是一个多维数组，那么峰度(X)沿X的第一个非单维操作。 正太分布的峰度是0； 当时间序列的曲线峰值比正太分布的高时，峰度大于0，即呈现尖峰分布； 当比正太分布的低时，峰度小于0，即呈现峰值比较平坦 skewness偏度函数 偏度能够反应分布的对称情况，右偏（也叫正偏），在图像上表现为数据右边脱了一个长长的尾巴，这时大多数值分布在左侧，有一小部分值分布在右侧。 y = skewness(X)返回X的样本偏度。 如果X是一个向量，那么skewness(X)返回一个标量值，该值是X中元素的偏度。 如果X是一个矩阵，那么skewness(X)返回一个包含X中每一列的样本偏度的行向量。 如果X是一个多维数组，则偏度(X)沿X的第一个非单维操作。 对于正太分布，偏度为0; 若偏度为正，则x均值左侧的离散度比右侧弱； 若偏度为负，则x均值左侧的离散度比右侧强。 与眼电相关 1.为什么要符合正态分布？ 有些模型的应用条件就是要求数据满足正态性分布的，比如说：贝叶斯、逻辑回归、KNN、Kmean等设计到概率分布、参数距离比较等，转换为正态分布，模型条件更充足。 其次，正态分布，数据的泛化性高。因为自然界很多事物的概率密度很大是正态分布的。 最后，从目标分布来说，偏态分布会导致label数据的MSE出现误导，或许结果看着很小，但实际结果很大。 判断数据是否服从正态分布的指标：偏度(skewness)和峰度(kurtosis) ","link":"https://monsterju.github.io/post/kurtosis-han-shu-yu-skewness-han-shu/"},{"title":"matlab的函数句柄@","content":"@的理解 作用是将一个函数封装成一个变量，使其能够像其它变量一样在程序的不同部分传递 类似C++的指针，即函数指针的调用。句柄分为多种，如函数柄，对象柄，图形柄等。 函数句柄的创建： 直接加@ 语法：@函数名fun1 = @sin; fun1=@sin; str2func函数 语法：str2fun(‘函数名’) fun2 = str2func(‘cos’); str2func函数 语法：@(参数列表)单行表达式 fun3 = @(x, y)x.^2 + y.^2; 函数句柄应用：函数句柄作为函数参数；利用函数句柄绘图；利用函数句柄滤波等 函数句柄的调用 假定一个函数的调用格式为：[y1,y2,…,yn] = FunctionName(x1,x2,…,xm) 该函数通过以下方式构建函数句柄：Hfunction = @FunctionName 则通过函数句柄实现函数运算的调用格式是： 直接调用 Hfunction (x1,x2,…,xm) 或者 [y1,y2,…,yn]=feval (Hfunction,x1,x2,…,xm) 图形句柄和图形之间是一种一一对应关系，简单的说图形句柄就是指向了这个图形的一个变量，通过它可以设定该图形的各种属性。图形句柄就指一个图形，在生成图形时同时得到一代号，如语句 h=plot(x,y),h 就是一个图形句柄，在后来的某一个地方就可用h代表这个图，如 set(h,…)，对这个图形进行再设置。 ","link":"https://monsterju.github.io/post/matlab-de-han-shu-ju-bing/"},{"title":"mat文件转化为excel文件","content":"1.首先把你需要转换的mat数据文件导入到工作区，默认命名data load('xxx.mat') %%xxx为需要转换的mat文件名 或者在matlab的当前文件夹区双击该文件，matlab自动导入数据 2.在命令行窗口输入（建议转成xls格式，python新的xrdl现在不支持xlsx格式，转换比较麻烦） xlswrite('yyy.xls',data) %%yyy为输出的excel文件名 转换好的Excel文件会自动保存在原mat文件同目录下。 注意 mat文件含有结构体，导出时只能导出数据，不能把结构 一起导出。 ","link":"https://monsterju.github.io/post/mat-wen-jian-zhuan-hua-wei-excel-wen-jian/"},{"title":"面试问题","content":" 自然界的语言有哪些类型？如何识别？ 什么是图灵测试？什么是机器学习？ 计算机如何识别图像、语音等信息 有哪些常用的排序算法，它们的时间复杂度是多少？ 给出贝叶斯公式和它表达的含义 操作系统的五个基本步骤 无人驾驶中有哪些与人工智能相关的部分？ 中国人工智能的起源、发展、现状？ 人工智能在生活中的例子 什么是维和度的概念？ 范数的概念？ 请解释马尔可夫模型、泰勒展开式 对于技术和科研是你是怎么看待的？ 研究生阶段的学习与本科阶段有何不同？ 自干五和五毛是什么意思？ 冯诺依曼体系结构的设计思想和组成 情感机器人在照顾老年人方面的应用 线性代数为何叫线性代数 自然语言处理与自然语言理解的区别和联系 什么是智能机器人，你认为智能机器人在哪个行业的应用有前景 AI有哪些是和人类的思考方式类似的？ 在哪些方面机器智能可以超越人类智能，在哪些方面永远不行？ 谈谈cv与nlp的应用 人类的视觉系统与计算机的视觉系统有何区别 大数据是什么？数据挖掘又是什么？ Windows与linux的区别 栈和队列在操作系统中的应用 插值算法是什么，请介绍几个插值算法 为什么程序=数据结构+算法 请解释区块链 人类的学习方式有哪几种 请给出计算机网络的定义 脑机接口、类脑计算的概念 请介绍几个国内外AI名人 请给出程序、进程、线程之间的区别和联系 请解释PCA与MDS ","link":"https://monsterju.github.io/post/mian-shi-wen-ti/"},{"title":"机器学习的分类模型","content":"分类模型将特征空间划分为多个区域，每个区域用一个合适的输出类别进行标注，是通过训练数据并应用给定的过程（即机器学习方法）得到的。 机器：一台遵循方法的计算机 学习：得到的模型是取决于使用的训练数据 机器学习工具箱 可视化： 使用箱线图是一种可视化多个分布的简单方法。 boxplot(x,c) 这将创建一个箱线图，它的箱子表示 c 中每个类的 x 值的分布。如果各个类的 x 值显著不同，则 x 可以作为区分这些类的特征。能够区分不同类的特征越多，就越有可能根据完整数据集来构建准确的分类模型。 执行预测 predict 函数来获得模型对新数据的预测。 preds = predict(model,newdata) 使用 ~= 运算符确定误分类率（不正确预测数除以预测总数）。将结果存储在名为 misclassrate 的变量中。 iswrong = predLetter~=testdata.Character misclassrate = sum(iswrong)/numel(iswrong) 在训练或测试数据中，响应类不总是均匀分布的。损失是一种更合理的误分类度量，它包含每个类的概率（基于数据中的分布）。 loss(model,testdata) 计算已知正确类的任何数据集的损失。尝试确定原始训练数据 (traindata) 的损失。这称为再代入损失（当训练数据“再代入”模型时的损失）。可以直接用 resubLoss(knnmodel) 计算再代入损失。 识别误分类 生成混淆图时，您可以通过分别添加行或列汇总来补充关于每个类的假负和假正率的信息。 confusionchart(...,&quot;RowSummary&quot;,&quot;row-normalized&quot;); 行汇总显示每个类的假负率。这会显示 kNN 模型最难识别的字母（即模型最容易识别为其他字母的字母）。有些混淆似乎是合理的，如 U/V 或 H/N。有些混淆则更出乎意料，如 U/K。确定感兴趣的误分类后，可能希望查看一些特定的数据采样，以了解误分类的原因。 falseneg 的逻辑数组，该数组能标识将字母 U 误分类为其他字母的测试数据实例。即，真实类 (testdata.Character) 是“U”而预测类 (predLetter) 不是“U”的元素。 使用逻辑数组 falseneg 作为 testfiles 的索引来确定被不正确分类为字母 U 的观测值的文件名。 使用 falseneg 作为 predLetter 的索引来确定相关联的预测字母。 使用 readtable 函数将 fnfiles 的第四个元素中的数据导入名为 badU 的表中。通过绘制 Y 对 X 的图来可视化字母。 falseneg = (testdata.Character == &quot;U&quot;) &amp; (predLetter ~= &quot;U&quot;) fnfiles = testfiles(falseneg) fnpred = predLetter(falseneg) badU = readtable(fnfiles(3)) plot(badU.X,badU.Y) title(&quot;Prediction: &quot;+string(fnpred(3))) 调查误分类 对于任一响应类 X，您可以将一个机器学习模型的预测分为四个组： 真正- 预测为 X 且实际为 X 真负- 预测不为 X 且实际不为 X 假正- 预测为 X 但实际不为 X 假负- 预测不为 X 但实际为 X 提取特征数据 使用逻辑索引仅提取字母 N 和 U 的训练数据 提取其中字母 U 被误分类（即 U 的假负）的测试数据 idx = (traindata.Character == &quot;U&quot;) | (traindata.Character == &quot;N&quot;) UorN = traindata(idx,:) falidx = (testdata.Character == &quot;U&quot;) &amp; (predLetter ~= &quot;U&quot;) %U的假负 fnU = testdata(falidx,:) 清理 分类变量保存着可能类的完整列表，即使有时数据中只存在部分类。当研究部分类时，重新定义可能类的集，将其限定于数据中包含的类，这样会很有用。removecats 函数删除未使用的类别。 ```matlab cmin = removecats(cfull) 提取特征 可以使用花括号 ({ }) 将数据从表中提取到单一类型的数组中。 datamatrix = datatable{1:10,4:6} 这将提取变量 4、5 和 6 的前 10 个元素。如果这些变量为数值类型，datamatrix 将是一个 10×3 双精度数组。 绘制 平行坐标图将每个观测值的特征值（或“坐标”）显示为一条线。 要比较不同类的特征值，请使用 &quot;Group&quot; 选项 parallelcoords(UorNfeat,&quot;Group&quot;,UorN.Character) 通过分类学习器可以轻松地使用不同模型进行试验。也可以尝试其他方式，例如，对于 kNN 模型，可以更改邻点的数量、基于距离的邻点的权重以及距离的定义方式。 一些分类方法对训练数据高度敏感，这意味着使用基于不同数据子集训练的不同模型，获得的预测可能差异很大。我们可以利用这一点来建立一个集成模型，将其转化为优势，集成模型使用训练数据的不同排列来训练大量所谓的弱学习器，并使用各个预测的分布来进行最终预测。 在字迹示例中，一些字母对组（例如 N 和 V）具有许多相似的特征，只能通过一个或两个关键特征来区分。这意味着基于距离的方法（如 kNN）可能难以处理这些对组。另一种方法是使用名为纠错输出编码 (ECOC) 的集成方法，用多个模型来区分不同的二类对组。也就是说，用一个模型区分 N 和 V，用另一本模型区分 N 和 E，再用一个模型区分 E 和 V，依此类推。 ","link":"https://monsterju.github.io/post/ji-qi-xue-xi-de-fen-lei-mo-xing/"},{"title":"特征工程","content":"机器学习算法需要特定形式的数据结构。信号带有许多的特征可用于区分不同的事物。构建预测模型时，这些特征作为预测输入。需要将原始数据转化为一组特征。特征是整个信号的简单 统计度量、形状的度量，如局部最大数目或波峰的宽度、相关性的度量或任何数量的其他度量。有针对声音、振动或心跳等周期信号的方法，这些方法一般把一个信号分解成若干个简单分量并确定各个分量对整个信号的贡献。可以把许多周期性信号表示为不同频率的正弦和余弦的组合。 统计函数 集中趋势的度量 函数 说明 mean 算术均值 median 中位数（中间）值 mode 出现次数最多的值 trimmean 截尾均值（均值，不包括离群值） geomean 几何均值 harmean 调和均值 散布的度量 函数 说明 range 值的极差（最大 - 最小） std 标准差 var 方差 mad 均值绝对偏差 iqr 四分位差（第 75 个百分位数减去第 25 个百分位数） 形状的度量 函数 说明 skewness 偏度（第三个中心矩） kurtosis 峰度（第四个中心矩） moment 任意阶中心矩 描述性统计量 计算汇总统计量（量化字母形状） 字迹采样均进行了偏移处理，使它们在水平和垂直位置的均值都为零。与均值相比，中位数对离群值较不敏感。将均值与中位数进行比较，可以了解分布的不对称程度。值的散布可以用均值绝对偏差 (MAD)、标准差和方差来衡量。上述每一项都计算一种偏离均值的度量的平均值。默认情况下 mad 会忽略 NaN。 纵横比 中位数 均值绝对偏差 aratiovb = range(b1.Y)/range(b1.X) medxb = median(b1.X,&quot;omitnan&quot;) medyb = median(b1.Y,&quot;omitnan&quot;) devxb = mad(b1.X) devyb = mad(b1.Y) 不同字母的值如何比较？这些统计量会是有用的特征吗？ b与d的比较：中位数（水平值） b为负，d为正 查找峰值 局部最小值和最大值通常是信号的重要特征。islocalmin 和 islocalmax 函数接受信号作为输入，并返回与该信号长度相同的逻辑数组。 idxmin = islocalmin(x); idxmax = islocalmax(x); 当 idx 在信号中的对应值为局部最小/大值时，它的值为 true。 通过计算信号中每个值的相对高差来定义局部最小值和最大值。相对高差用于度量一个值与其周围其他值的相对差别程度。您可以通过 islocalmin 或 islocalmax 的第二个输出来获得信号中每个点的相对高差值。 [idx,prom] = islocalmin(x); prom为峰值； 默认情况下，islocalmin 和 islocalmax 将查找任何相对高差值大于 0 的点。这意味着按照定义，任意点只要大于位于其两侧的两个值，即为最大值。对于含噪信号，可能只想考虑相对高差高于给定阈值的最小值和最大值。 idx = islocalmin(x,&quot;MinProminence&quot;,threshvalue) 选择阈值时，请注意相对高差值的范围可以从 0 到 range(x)。 将 idxmin 传递给 nnz 或 sum 函数来对最小值计数。不同信号中局部最小值和最大值的数目不同。 计算导数 平板电脑记录的原始数据只包含不同时间的位置信息（没有速度），因此必须从原始数据计算速度。对于离散数据点，这意味着需要通过使用有限差分逼近 v=Δx/Δt 来估计速度。 diff 函数计算数组中连续元素之间的差值。即，如果 y = diff(x)，则 y1=x2−x1，y2=x3−x2，以此类推。请注意，y 比 x 少一个元素。 将 dX 除以 dT 来计算 m2.X 的近似导数。请记住使用数组除法运算符(./) diff 函数的输出比输入少一个元素。绘制dXdT 随 m2.Time 变化的图，不包括最终值可以使用 end 关键字来引用数组中的最后一个元素。 dY = diff(m2.Y) dX = diff(m2.X); dT = diff(m2.Time); dYdT = dY./dT dXdT = dX./dT maxdx = max(dXdT) maxdy = max(dYdT) plot(m2.Time(1:end-1),dXdT) ♦️受数据采集过程的分辨率限制，数据会包含一些重复值。如果位置和时间都重复，则差值都是 0，这会得到导数 0/0 = NaN。然而，如果位置值有极微小的差异，则导数为 Inf（非零值除以 0）。 请注意，max 会忽略 NaN 但不会忽略 Inf，因为 Inf 大于任何有限值。然而，这里的应用可以忽略 NaN 和 Inf，因为它们表示重复数据。 可以使用 standardizeMissing 函数将一系列值转换为 NaN（或非数值数据类型的缺失值）。 xclean = standardizeMissing(x,0); dYdT = standardizeMissing(dYdT,Inf) xclean = standardizeMissing(x,[-Inf 0 Inf]); 在此处，xclean 与 x 相同（包括其中的任何 NaN），只是在 x 具有值 0 的对应位置都会转换为 NaN。dYdT的所有Inf值全部转化为Nan。负值被零除将得到 -Inf。可以将值的向量传递给 standardizeMissing ，以便一次处理多个缺失值。 计算相关性 对于字母 V 的前半部分，水平和垂直位置有很强的负线性相关性：随着水平位置增大，垂直位置成比例减小。同样，对于后半部分，两个位置具有很强的正相关性：随着水平位置增大，垂直位置也成比例增大。 corr 函数计算变量之间的线性相关性。 C = corr(x,y); C = corr(v2.X,v2.Y,&quot;Rows&quot;,&quot;complete&quot;) 由于两个变量都包含缺失数据，C 为 NaN。将 &quot;Rows&quot; 选项设置为 &quot;complete&quot;，来比避免缺失值。 相关系数始终在 -1 和 +1 之间。 当系数为 -1时， 表示完全负线性相关 当系数为 +1 时，表示完全正线性相关 当系数为 0 时，表示无线性相关。 计算每对变量之间的相关性，可以将矩阵传递给 corr 函数，其中每个变量均为矩阵的一列。 M = [a b c d]; Cmat = corr(M,&quot;Rows&quot;,&quot;complete&quot;); 输出 Cmat 是一个 4×4 矩阵，其中包含 M 的两两列之间的相关系数。即 Cmat(j,k) 是 M(:,j) 和 M(:,k) 之间的相关性。该矩阵是对称矩阵，因为 x 和 y 之间的相关性与 y 和 x 之间的相关性相同。对角线元素始终等于 1，因为变量始终与自身完美相关。 M 的前两列是信号的前半部分的水平和垂直位置；最后两列是信号的后半部分的水平和垂直位置。对于字母 V ，即前两列是负相关，后两列正相关。 自动化特征提取 一旦确定了要提取的特征，就需要对数据集中的每个采样应用适当的计算。自动化此过程的第一步是创建一个自定义函数，该函数接受数据作为输入，并返回一个特征数组作为输出。 load sampleletters.mat letter = b1; featB1 = extract(letter) function feat = extract(letter) % Aspect ratio aratio = range(letter.Y)/range(letter.X); % Local max/mins idxmin = islocalmin(letter.X,&quot;MinProminence&quot;,0.1); numXmin = nnz(idxmin); idxmax = islocalmax(letter.Y,&quot;MinProminence&quot;,0.1); numYmax = nnz(idxmax); % Velocity dT = diff(letter.Time); dXdT = diff(letter.X)./dT; dYdT = diff(letter.Y)./dT; avgdX = mean(dXdT,&quot;omitnan&quot;); avgdY = mean(dYdT,&quot;omitnan&quot;); % Correlation corrXY = corr(letter.X,letter.Y,&quot;rows&quot;,&quot;complete&quot;); % Put it all together into a table featurenames = [&quot;AspectRatio&quot;,&quot;NumMinX&quot;,&quot;NumMinY&quot;,&quot;AvgU&quot;,&quot;AvgV&quot;,&quot;CorrXY&quot;]; feat = table(aratio,numXmin,numYmax,avgdX,avgdY,corrXY,'VariableNames',featurenames); end 需要数据存储在每次读取数据时应用提取函数。 多个数据文件中提取特征 文件名包含数据表示的字母，其形式为 usernnn_X_n.txt。请注意，字母名称出现在下划线字符之间 (X)。可以使用 extractBetween 函数提取出现在给定字符串之间的文本。 extractedtxt = extractBetween(txt,&quot;abc&quot;,&quot;xyz&quot;) 如果 txt 是字符串数组 [&quot;hello abc 123 xyz&quot;,&quot;abcxyz&quot;,&quot;xyzabchelloxyzabc&quot;]，则 extractedtxt 将是 [&quot; 123 &quot;,&quot;&quot;,&quot;hello&quot;]。 对于分类问题，通常希望将已知标签表示为分类变量。您可以使用 categorical 函数将数组转换为分类类型。 xcat = categorical(x) 默认情况下，x 中的唯一值将用于定义类别集。 letterds = datastore(&quot;*.txt&quot;); preprocds = transform(letterds,@scale) featds = transform(preprocds,@extract) data = readall(featds) knownchar = extractBetween(letterds.Files,&quot;_&quot;,&quot;_&quot;) knownchar = categorical(knownchar) data.Character = knownchar gscatter(data.AspectRatio,data.CorrXY,data.Character) function data = scale(data) % Normalize time [0 1] data.Time = (data.Time - data.Time(1))/(data.Time(end) - data.Time(1)); % Fix aspect ratio data.X = 1.5*data.X; % Center X &amp; Y at (0,0) data.X = data.X - mean(data.X,&quot;omitnan&quot;); data.Y = data.Y - mean(data.Y,&quot;omitnan&quot;); % Scale to have bounding box area = 1 scl = 1/sqrt(range(data.X)*range(data.Y)); data.X = scl*data.X; data.Y = scl*data.Y; end function feat = extract(letter) % Aspect ratio aratio = range(letter.Y)/range(letter.X); % Local max/mins idxmin = islocalmin(letter.X,&quot;MinProminence&quot;,0.1); numXmin = nnz(idxmin); idxmax = islocalmax(letter.Y,&quot;MinProminence&quot;,0.1); numYmax = nnz(idxmax); % Velocity dT = diff(letter.Time); dXdT = diff(letter.X)./dT; dYdT = diff(letter.Y)./dT; avgdX = mean(dXdT,&quot;omitnan&quot;); avgdY = mean(dYdT,&quot;omitnan&quot;); % Correlation corrXY = corr(letter.X,letter.Y,&quot;rows&quot;,&quot;complete&quot;); % Put it all together into a table featurenames = [&quot;AspectRatio&quot;,&quot;NumMinX&quot;,&quot;NumMinY&quot;,&quot;AvgU&quot;,&quot;AvgV&quot;,&quot;CorrXY&quot;]; feat = table(aratio,numXmin,numYmax,avgdX,avgdY,corrXY,'VariableNames',featurenames); end ","link":"https://monsterju.github.io/post/te-zheng-gong-cheng/"},{"title":"信号类型","content":"机器学习算法需要特定形式的数据结构。信号带有许多的特征可用于区分不同的事物。构建预测模型时，这些特征作为预测输入。需要将原始数据转化为一组特征。特征是整个信号的简单 统计度量、形状的度量，如局部最大数目或波峰的宽度、相关性的度量或任何数量的其他度量。有针对声音、振动或心跳等周期信号的方法，这些方法一般把一个信号分解成若干个简单分量并确定各个分量对整个信号的贡献。可以把许多周期性信号表示为不同频率的正弦和余弦的组合。 ","link":"https://monsterju.github.io/post/xin-hao-lei-xing/"},{"title":"导入和预处理数据","content":"导入和预处理数据 创建数据存储 使用通配符(*或?)为匹配特定模式的文件或文件夹创建一个数据存储。 letterds= datastore(&quot;*_M_*.txt&quot;) 使用 datastore 函数为所有包含字母 M 的文件创建一个数据存储。这些文件的名称中包含 M，扩展名为 .txt。将该数据存储存储在名为 letterds 的变量中。 可以使用 read 函数从数据存储的文件中导入数据。 data = read(letterds); 第一次使用 read 函数将从第一个文件导入数据。第二次使用该函数将从第二个文件导入数据，依此类推。 readall 函数将数据存储中所有文件的数据导入单个变量中 data = readall(letterds) 无法简单地确定来自一个文件的数据在哪里结束以及来自下一个文件的数据在哪里开始。造成特征无法准确提取 添加数据变化 通常，需要对原始数据的每个采样应用一系列预处理操作。自动化此过程的第一步是创建一个应用您的特定预处理操作的自定义函数。 在脚本的末尾添加自定义函数。对于数据预处理，该函数应接受从数据存储返回的数据作为输入。它应将变换后的数据作为输出返回。 function dataout = functionName(datain) % do something with datain dataout = ... end 要将一个函数用作另一个函数的输入，请通过在函数名称的开头添加 @ 符号来创建函数句柄。 transform(ds,@myfun) 函数句柄是对函数的引用。如果没有 @ 符号，MATLAB 会将函数名称解释为对该函数的调用。 典型的归一化包括按均值偏移（使偏移后的数据的均值为 0）或者将数据偏移并缩放到固定范围内（例如 [-1, 1]）。对书写的字母的 x 和 y 数据都进行偏移，使其均值为 0，这将确保所有字母都以同一点为中心。 两个分量中减去均值位置： data.X = data.X - mean(data.X); data.Y = data.Y - mean(data.Y); 请注意，这会造成问题，使绘图显示空白。 任何涉及 NaN 的计算（包括以默认方式使用 mean 之类的函数）都将得到 NaN。这在机器学习中很重要，因为在机器学习中，数据经常有缺失值。在字迹数据中，只要书写者将触笔从平板电脑提起，就会出现一个 NaN。 可以使用 &quot;omitnan&quot; 选项让 mean 之类的统计函数忽略缺失值。 mean(x,&quot;omitnan&quot;) letterds = datastore(&quot;*_V_*.txt&quot;); data = read(letterds); data = scale(data); plot(data.X,data.Y) axis equal plot(data.Time,data.Y) ylabel(&quot;Vertical position&quot;) xlabel(&quot;Time&quot;) preprocds = transform(letterds,@scale) data = readall(preprocds) plot(data.Time,data.Y) function data = scale(data) data.Time = (data.Time - data.Time(1))/1000; data.X = 1.5*data.X; data.X = data.X-mean(data.X,&quot;omitnan&quot;) data.Y = data.Y-mean(data.Y,&quot;omitnan&quot;) end ","link":"https://monsterju.github.io/post/prepro/"},{"title":"触屏手写字母J、M、V的识别分类","content":"基于matlab实现，采用knn算法 导入数据 可以使用 readtable 函数从电子表格或文本文件导入表格数据，并将结果以表的形式存储。 letter = readtable(&quot;M.txt&quot;); plot(letter.X,letter.Y) axis equal 默认轴范围会使字母的纵横比失真。您可以使用 axis 命令强制轴保持数据的纵横比。使用命令 axis equal 修正绘图的纵横比。 若不是正方形屏幕显示：将表 letter 的变量 X 中的值乘以纵横比 1.5。将结果重新赋给 X，使 letter 包含修正后的数据 处理数据 时间归一化：对表 letter 的 Time 变量进行偏移以从 0 开始，通过从所有元素中减去第一个值并将结果除以 1000 以转换为秒。将结果重新赋给 Time，使 letter 包含调整后的数据。 lette.time = (letter.time-letter.time(1))/1000 计算特征 这些字母的哪些特点可用于将 J 与 M 或 V 区分开来？我们的目标不是使用原始信号，而是计算出可将整个信号提取为简单、有用的信息单元的值，这些信息单元称为特征。 对于字母 J 和 M，一个简单的特征可能是纵横比（字母的高度相对于宽度的比例）。J 可能高而窄，M 可能更接近正方形。 与 J 和 M 相比，书写 V 的速度更快，因此信号的持续时间也可能是一个区分特征。 特征 持续时间:通过提取 letter.Time 的最后一个值并将结果存储在名为 dur 的变量中，来计算书写该字母所需的时间。 字母的纵横比：使用 range 函数通过将 letter.Y 的值极差除以 letter.X 的值极差来计算字母的纵横比。将结果赋给名为 aratio 的变量。 dur = letter.Time(end) aratio = range(letter.Y)/range(letter.X) range 函数返回数组中值的极差。即 range(x) 等效于 max(x) - min(x) 猜测结果： 字母M的纵横比更接近于1，持续时间较长 字母J、V的纵横比较大，持续时间较短，V更短 提取特征 尚不清楚这些特征是否足以区分数据集中的三个字母（J、M 和 V）: 1.使用 scatter 函数绘制提取的特征，水平轴上为纵横比，垂直轴上为持续时间。但没有着色，所以区分不了特征是否足够 scatter(features.AspectRatio,features.Duration) 2.gscatter 函数生成一个分组散点图 - 即根据分组变量对点进行着色的散点图。gscatter(x,y,g)，使用 gscatter 函数创建散点图，根据字母(g)进行着色，字母存储在表 features 的 Character 变量中。 gscatter(features.AspectRatio,features.Duration,features.Character) 建立模型 没有一种绝对“正确”的方法将平面划分为 J、M 和 V 类。不同分类算法会产生不同划分。 一个简单模型是将一个观测值与最邻近的已知示例划分为相同的类。这称为 k 最近邻 (kNN) 模型。您可以通过将数据表传递给 fitcknn 函数来拟合 kNN 模型。 mdl = fitcknn(data,&quot;ResponseVariable&quot;); 第二个输入是表中响应变量的名称（即模型要预测的类）。输出是包含拟合模型的变量。 knnmodel = fitcknn(features,&quot;Character&quot;) 使用 fitcknn 函数对 features 中存储的数据进行模型拟合。已知的类存储在名为 Character 的变量中。将生成的模型存储在名为 knnmodel 的变量中。 预测 根据数据建立模型后，您可以使用它对新观测值进行分类。这只需计算新观测值的特征并确定它们位于预测变量空间的哪个区域。 predict 函数用于确定新观测值的预测类。 predClass = predict(model,newdata) 输入是经过训练的模型和新观测值。输出是 newdata 中每个观测值的预测类的分类数组。 通常情况下，新观测值以表的形式出现，其预测变量与用于训练模型的预测变量相同。然而，在本例中，模型使用了两个数值特征（纵横比和持续时间），因此观测值也能以具有两列的数值数组形式出现。 使用 predict 函数和经过训练的模型 knnmodel 对纵横比为 4、持续时间为 1.2 的一个字母进行分类。将预测存储在名为 predicted 的变量中。以二元素行向量形式提供字母特征。 newdata = [4,1.2] predicted = predict(knnmodel,newdata) 预测结果为 V k值选择 默认情况下，fitcknn 用 k= 1 对 kNN 模型进行拟合。也就是说，该模型仅使用最邻近的已知示例对给定观测值进行分类。因而模型对训练数据中的任何离群值都敏感，例如上图中突出显示的离群值。离群值附近的新观测值可能被误分类。 可以通过增大 k 的值（即，使用若干邻点的最常见类），使模型对训练数据中的特定观测值不太敏感。这通常会提高模型的总体性能。然而，模型在任何特定测试集上的性能取决于该测试集中的具体观测值。 通过在调用 fitcknn 时设置 &quot;NumNeighbors&quot; 属性，可以在 kNN 模型中指定 k 的值。 mdl = fitcknn(data,&quot;ResponseVariable&quot;,...&quot;NumNeighbors&quot;,10); knnmodel = fitcknn(features,&quot;Character&quot;,NumNeighbors=5) newdata = [4,1.2] predicted = predict(knnmodel,newdata) 重新生成模型 得到预测结果：J 。发现更改邻点的数量改变了对要测试的观测值的预测。 通过将新数据的矩阵或表传递给 predict 函数，可以获得对多个观测值的预测。 输入原始数据测试❌ predictions = predict(knnmodel,features) 可以串联分类数组来并排查看预测和真实类。[predictions,features.Character] 输入测试集测试 predictions= predict(knnmodel,testdata) 评估模型 测试观测值的已知所属类存储在表 testdata 的变量 Character 中。 iscorrect= (predictions==testdata.Character) accuracy = sum(iscorrect)/numel(iscorrect) 将正确预测数除以预测总数，计算出正确预测的比例。将结果存储在名为 accuracy 的变量中。可以使用 sum 函数确定正确预测数，使用 numel 函数来确定预测总数。 但常用的评估模型指标是误分类率（不正确预测的比例），而不是准确度（正确预测的比例）。 iscorrect= predictions~=testdata.Character misclassrate = sum(iscorrect)/numel(iscorrect) 准确度和误分类率使用单个值来描述模型的整体性能，但进一步细分模型混淆了哪些类可能会很有用。 混淆矩阵显示真实类和预测类的每个组合的观测值数目。混淆矩阵通常根据元素的值给元素着色来实现可视化。通常，对角线元素（正确分类）用同一种颜色着色，其他元素（不正确分类）用另一种颜色着色。可以使用 confusionchart 函数来可视化混淆矩阵。 confusionchart(ytrue,ypred);其中 ytrue 是已知类的向量，ypred 是预测类的向量。 confusionchart(predictions,testdata.Character) 误分类观察 调查经常混淆的类的特征会很有用。尝试使用不正确分类的逻辑数组对 testdata 和 predictions 进行索引，以获得被误分类的观测值的数据。 data1 = testdata((iswrong ==1),:) pre= predictions((iswrong ==1),:) 发现误判在重叠区 以同样流程尝试13个字母的分类 %导入数据 load featuredata13letters.mat %观测值绘图 gscatter(features.AspectRatio,features.Duration,features.Character) %建立模型 knnmodel= fitcknn(features,&quot;Character&quot;,NumNeighbors=5) predictions= predict(knnmodel,testdata) %评估模型 iswrong= predictions~=testdata.Character misclass= sum(iswrong)/numel(iswrong) confusionchart(testdata.Character,predictions) ··· ![](https://monsterju.github.io/post-images/1680353859983.png) 只有两个特征模型（用于区分三个特定字母）的模型无法泛化到许多字母。 ","link":"https://monsterju.github.io/post/hong-ping-shou-xie-zi-mu-jmv-de-shi-bie-fen-lei/"},{"title":"matlab官方教程","content":"站点 clear:清空工作区 clc:清空命令行 save datafile.mat data 将数据保存到文件datafile.mat中 load myData.mat m 将从文件myData.mat中提取数据m format long/short:控制显示数据的精度位数 实时编辑器 可备注、可将按顺序执行命令行代码，并将每一步输出实时显示在右侧窗格中，可以看到代码与数据的联系。 运行符、分节符 文本与代码转换： ctrl+e 数组运算 x = 1:0.1:2 x= linspace(1,10,5) %(起始，终止，个数) 创建等距变量 x= x' %转置 x= rand(7,8) %0-1的随机数 x= zeros(3,4) 矩阵运算 .* x = [1 2;3 4;5 6; 7 8].*[1;2;3;4] x = [1 2;3 4;5 6; 7 8].^2 您可以使用关系运算符将某个向量或矩阵与单个标量值进行比较。结果是与原始数组相同大小的逻辑数组。 [5 10 15] &gt; 12 ans = 0 0 1 可以使用逻辑数组作为数组索引，在这种情况下，MATLAB 会提取索引为 true 的数组元素。以下示例将会提取 v1 中大于 6 的所有元素。也可以对两个不同向量使用逻辑索引 v = v1(v1 &gt; 6) v = sample(v1 &gt; 6) 索引 下标从1开始 data(row,col) data(:,col) data(end,col) 如果只对一个矩阵使用一种索引，它将按顺序从上到下遍历每列 y = density([1,3,6]) 索引可以是非连续数字。试着提取 density 的第一个、第三个和第六个元素。 基本函数 round:():四舍五入，&lt;0.5的值为0，&gt;0.5的值为1 函数可以应用于矩阵，以生成单个输出变量或两个输出变量。使用方括号 ([ ]) 获得多个输出。 如：使用 max 函数确定向量的最大值及其对应的索引值。max 函数的第一个输出为输入向量的最大值。执行带两个输出的调用时，第二个输出为索引值。 如果只需函数的第二个输出，可以使用波浪号字符 (~) 忽略特定输出。 绘图 每个绘图命令都创建了一个单独的绘图。要在一张图上先后绘制两条线，请使用 hold on 命令保留之前的绘图，然后添加另一条线。启用保留状态时，将继续在同一坐标区上绘图。要恢复默认绘图行为，即其中每个绘图都有自己的坐标区，请输入 hold off。 当您单独绘制一个向量时，MATLAB 会使用向量值作为 y 轴数据，并将 x 轴数据的范围设置为从 1 到 n（向量中的元素数目）。 plot 函数接受可选的附加输入，这些输入由一个属性名称和一个关联的值组成。 plot(y,&quot;LineWidth&quot;,5) 您注意到绘图的动画效果了吗？代码 pause(0.2) 在 0.2 秒处停止循环，以便绘图进行更新。请尝试通过增大值 0.2 来增加动画时间。 可以将字符串数组直接传递给 legend 函数。 默认轴范围会使字母的纵横比失真。您可以使用 axis 命令强制轴保持数据的纵横比。 任务 使用命令 axis equal 修正绘图的纵横比。 导入表格 要提取表变量，可以使用圆点表示法： data.VariableName 如果您正在使用表，您可能希望将相关数据放在一起。您可以将计算结果赋给表，而不是创建单独的变量。 data.HeightMeters = data.HeightYards*0.9144 如果变量 data.HeightMeters 不存在，MATLAB 将在表中创建名为 HeightMeters 的新变量。 可以通过在实时脚本的输出窗格中点击表来与表进行交互。例如，您可以使用表的一个变量对表进行排序。 ","link":"https://monsterju.github.io/post/matlab-guan-fang-jiao-cheng/"},{"title":"注意力机制","content":"self attention,用来自动学习和计算输入数据对输出数据的贡献大小。简单来说就是对于模型的每一个输入项，可能是图片中的不同部分，或者是语句中的某个单词分配一个权重，这个权重的大小就代表了我们希望模型对该部分一个关注程度。这样一来，通过权重大小来模拟人在处理信息的注意力的侧重，有效的提高了模型的性能，并且一定程度上降低了计算量。注意力机制通常可分为三类：软注意（全局注意）、硬注意（局部注意）和自注意（内注意）。 Soft/Global Attention(软注意机制)：对每个输入项的分配的权重为0-1之间，也就是某些部分关注的多一点，某些部分关注的少一点，因为对大部分信息都有考虑，但考虑程度不一样，所以相对来说计算量比较大。 Hard/Local Attention(硬注意机制)：对每个输入项分配的权重非0即1，和软注意不同，硬注意机制只考虑那部分需要关注，哪部分不关注，也就是直接舍弃掉一些不相关项。优势在于可以减少一定的时间和计算成本，但有可能丢失掉一些本应该注意的信息。 Self/Intra Attention（自注意力机制）：对每个输入项分配的权重取决于输入项之间的相互作用，即通过输入项内部的&quot;表决&quot;来决定应该关注哪些输入项。和前两种相比，在处理很长的输入时，具有并行计算的优势。（词与词之间存在一定关系，语义上下文） 机器翻译(机器翻译是最能体现注意力机制特色的任务。用注意力机制的直接目的，就是为输入的各个维度打分，然后按照得分对特征加权，以突出重要特征对下游模型或模块的影响。人在翻译的时候，在决定目标文本的某个词语时，会基于原文本的句法和语义，以及已确定的目标文本片段，从大脑的词汇表中找一个候选词语集合，然后在候选集中选一个最佳词语。 早期在解决机器翻译这一类序列到序列(Sequence to Sequence)的问题时，通常采用的做法是利用一个编码器(Encoder)和一个解码器(Decoder)构建端到端的神经网络模型。在编码器和解码器之间增加一个注意力模块。 一般会采用”key-query-value”理论来描述注意力机制的机理 特征工程 毕设的注意力检测有借鉴之处：通过注意力水平的高低作为权重（注意力得分计算模块、注意力的聚焦模块），区分当前的眼电数据的重要程度，来增强对游戏控制的灵敏度 ","link":"https://monsterju.github.io/post/zhu-yi-li-ji-zhi/"},{"title":"蚁群算法","content":"蚂蚁在寻找食物源时，会在其经过的路径上释放一种信息素，并能够感知其它蚂蚁释放的信息素。信息素浓度的大小表征到食物源路径的远近，信息素浓度越高，表示对应的路径距离越短。通常，蚂蚁会以较大的概率优先选择信息素浓度较高的路径，并释放一定量的信息素，以增强该条路径上的信息素浓度，这样会形成一个正反馈。最终，蚂蚁能够找到一条从巢穴到食物源的最佳路径，即最短距离。 TSP问题（Travel Salesperson Problem，即旅行商问题或者称为中国邮递员问题），是一种NP-hard问题，此类问题用一般的算法是很难得到最优解的，所以一般需要借助一些启发式算法求解，例如遗传算法（GA），蚁群算法（ACO），微粒群算法（PSO）等等。 TSP问题（旅行商问题）是指旅行家要旅行n个城市，要求各个城市经历且仅经历一次 然后回到出发城市，并要求所走的路程最短。一个TSP问题可以表达为：求解遍历图G=(V,E,C)，所有的节点一次并且回到起始节点，使得连接这些节点的路径成本最低。 蚁群算法原理 假如蚁群中所有蚂蚁的数量为m，所有城市之间的信息素用矩阵pheromone表示，最短路径为bestLength，最佳路径为bestTour。每只蚂蚁都有自己的内存，内存中用一个禁忌表（Tabu）来存储该蚂蚁已经访问过的城市，表示其在以后的搜索中将不能访问这些城市；还有用另外一个允许访问的城市表（Allowed）来存储它还可以访问的城市；另外还用一个矩阵（Delta）来存储它在一个循环（或者迭代）中给所经过的路径释放的信息素；还有另外一些数据，例如一些控制参数(α，β，ρ，Q)，该蚂蚁行走玩全程的总成本或距离（tourLength），等等。假定算法总共运行MAX_GEN次，运行时间为t。 蚁群算法计算过程如下： （1）初始化。 （2）为每只蚂蚁选择下一个节点。 （3）更新信息素矩阵。 （4）检查终止条件 如果达到最大代数MAX_GEN，算法终止，转到第（5）步；否则，重新初始化所有的蚂蚁的Delt矩阵所有元素初始化为0，Tabu表清空，Allowed表中加入所有的城市节点。随机选择它们的起始位置（也可以人工指定）。在Tabu中加入起始节点，Allowed中去掉该起始节点，重复执行（2），（3）,(4)步。 （5）输出最优值 思考：计算机网络联系；反过程 #距离-向量路由算法（路由信息协议RIP） 所有结点都定期将它们的整个路由选择表传递给与之相邻的结点。路由选择表包括每条路径的目的地和路径的代价；迭代计算一条路由中的站段数或延迟时间，从而得到到达一个目标的最短（最小代价）距离。 会出现慢收敛现象：蚁群沿着信息素多的路径走，也存在收敛速度慢，容易陷入局部最优（local optimal）等缺点。若路径出现错误，传递消息慢。在错误路径上蚂蚁越来越多，发现后在变少。 遗传算法 粒子群优化算法 模拟退火算法 ","link":"https://monsterju.github.io/post/yi-qun-suan-fa/"},{"title":"机器学习概论","content":"机器学习就是从数据中提取信息的方集合 概念问题 偏差与方差之间的权衡 偏差（bias)（模型拟合数据的程度）：由于ML算法中的假设不正确或或过于简单而导致的误差。度量了学习算法的期望预测与真实结果的偏离程度, 即刻画了学习算法本身的拟合能力 方差（variable）（模型基于输入的变化量）：由于ML算法的复杂性而导致的错误，从而对训练数据的高水平变化和过度拟合产生敏感性。度量了同样大小的训练集的变动所导致的学习性能的变化, 即刻画了数据扰动所造成的影响 换句话说，简单的模型是稳定的（低方差），但有很大的偏差，但代表了模型的真实性（低偏差）；复杂的模型容易过拟合，但表达了模型的真实性。 误差的最佳减少要权衡偏差和方差，以避免高方差和高偏差 过度拟合：低偏差、高方差--当学习器把训练样本学的“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。 原因：训练数据中噪音干扰过大，使得学习器认为部分噪音是特征从而扰乱学习规则；建模样本选取有误，例如训练数据太少，抽样方法错误，样本label错误等，导致样本不能代表整体；模型不合理，或假设成立的条件与实际不符；特征维度/参数太多，导致模型复杂度太高。 欠拟合：高偏差、低方差--指对训练样本的一般性质尚未学好。在训练集及测试集上的表现都不好。 原因：模型复杂度过低；特征量过少。 贝叶斯定理 提供先验知识事件的后验概率。用于模型拟合到训练数据集的概率框架中，并用于建立分类预测建模问题（朴素贝叶斯，贝叶斯最优分类器） 深度学习框架：Tensorflow、Pytouch、PaddlePaddle 数据集：有特征值和目标值构成的集合 MNIST：大型手写数字数据库 ImageNet：图像识别最大的数据库 PASCAL VOC：视觉对象的分类识别和检测的一个基准测试，提供了检测算法和学习性能的标准图形注释数据集和标准的评估系统 COCO：图像识别、分割和加字幕注释的数据集 特征工程包括什么？ 特征抽取、特征预处理、特征降维 特征提取：将任意数据转化为可用与机器学习的数字特征。例如：字典型特征提取、文本型特征提取 特征预处理：预先处理，包括归一化标准化、异常样本清洗、样本数据不平衡问题处理 特征降维：降低的对象是多维数组。降低的是特征的 个数，得到一组“不相关”的主变量的过程 分类、回归、聚类】降维的代表性算法： 分类：朴素贝叶斯、逻辑回归、决策树、K近邻算法、支持向量机算法 回归：线性回归、直线拟合、逻辑回归、logistic函数拟合 聚类：K-means算法 降维：主成分分析 人工智能应用：机器人领语、语言识别领域、图像识别领域、专家系统 卷积神经网络 为什么Dropout有效？ 防止参数过分依赖训练数据，增加参数对数据集的泛化能力 Dropout指的是让部分神经元失效或者状态抑制。在训练阶段，以概率p主动临时性的忽略掉部分隐藏节点。好处是在较大程度上减少网络的大小（解决耗时的问题），而且多个这样的抑制不同隐藏神经元的网络组合可以解决过拟合的问题。 典型的优化算法 遗传算法 模拟退火算法 蚁群算法 粒子群算法 强化学习：用于描述和解决智能体在于环境的交互过程中通过学习策略以达到汇报最大化或实现特定目标的问题；有机体如何在环境给予的奖励或刺激下，逐步形成对刺激的预期，产生能获得最大收益的习惯性行为。 迁移学习：把已训练好的模型（预训练模型）参数迁移到新的模型来帮助新模型训练。 Transfer Learning：冻结预训练模型的额全部卷积层，只训练自己定制的全连接层 Extract Feature Vector：先计算出预训练模型的卷积层对所有训练和测试数据的特征向量，然后抛开预训练模型，只训练自己定制的简配版简配版全连接网络 Fun-tuning：冻结预训练模型的部分卷积层，甚至不冻结任何网络层，训练剩下的额卷积层和全连接层 常见的评价指标 分类：精确度、召回率、准确率、F值、ROC-AUC、混淆矩阵、PRC 回归：RMSE（平方根误差）、MAE（平均绝对误差）、MSE（平均平方误差） 聚类：兰德指数、互消息、轮廓指数 batch的大小对训练的影响 batch_size决定了下降的方向 合理范围内增大，提高内存利用率及大矩阵乘法的并行化效率；跑完一次epoch所需的迭代次数减少，处理速度更快；越大，下降方向越准，引起的训练震荡越小 盲目增大，内存容量可能撑不住；迭代次数减少，精度下降，对参数的修正也更慢；增大到一定程度，其确定的下降方向基本不再变化 设的小一些，收敛的慢，可能准确率来回震荡，需把基础学习速率降低一些，但可使实际使用精度较高 生成模型和判别模型的区别 生成模型会学习数据的分布；判别模型学习的是不同数据之间的区别，不学习数据内部特点。 生成模型求解：联合分布--求解类别先验概率和类别条件概率 判别模型求解：条件分布--模型参数后验概率最大--（拟然函数/cdot参数先验）最大--最大拟然 生成方法：混合高斯模型、朴素贝叶斯法和隐形马尔可夫模型等 判别方法：SVM、LR gan（对抗生成网络） 假设我们有两个网络，G（Generator）和D（Discriminator) G是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片，记作G(z) D是判别网络，判一张图片是不是真实的。输入参数是x，输出D(x)代表真实图片的概率。 动态博弈过程：最理想情况下，最终G可以生成以假乱真的图片G(z)，而D(G(z))=1 得到一个生成式的模型G，用来生成图片 监督学习与无监督学习 监督学习，其基本思想是，我们数据集中的每个样本都有相应的“正确答案”，再根据这些样本作出预测， 回归问题，即通过回归来推出一个连续的输出 分类问题，其目标是推出一组离散的结果 无监督学习中没有任何的标签或者是有相同的标签。已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集 聚类算法 ","link":"https://monsterju.github.io/post/MLqa/"},{"title":"面向对象","content":"特征 封装 封装是保证软件内部具有优良的模块性的基础，防止程序相互依赖而带来的变动影响。面对对象的封装就是把描述一个对象的属性和方法的代码封装到一个“模块”中或者时一个“类”中，属性用变量定义，行为用方法定义，方法可以直接访问同一个对象中的属性。一般把一个类的成员变量全部定义为私有 原则是把对同一事物进行操作的方法和相关的方法放在同一个类中，把方法和他操作的数据放在同一个类中。 抽象 就是找出一些事物的相似和共性之处，然后把这些事物归为一类。忽略与当前主题和目标无关的那些方面 继承 再定义一个类的时候，可以在一个已经存在的类的基础上来进行，把这个已经存在的类所定义的内容作为自己的内容，并可以添加若干新的内容，或修改原来的方法使之更适合特殊要求。子类继承共享父类资源（数据或方法），可提高软件的可重用性和可扩展性。 多态 按字面的意思就是多种形态。当类之间存在层次结构，并且类之间是通过继承关联时，就会用到多态。 C++ 多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的调用在该编程时不确定，在程序运行期间才能确定。即一个引用变量会指向哪一个类的实例对象，该引用变量发出的方法调用是哪个类中的实现方法，必须在运行程序时才能确定。有了多态，可以有多个不同的类，都带有同一个名称但具有不同实现的函数，函数的参数甚至可以是相同的。增加软件的灵活性和拓展性。 虚函数vitural声明 常见问题 类与对象的关系 类是一种数据结构，将不同类型的数据与这些数据相关的操作封装在一起的集合体。关键是数据抽象和封装。包含了数据表示法和用于处理数据的方法 对象是指将类实例化的实体，具体的事物或者抽象的事物 类与结构体 C语言只有结构体，C++两个都有 C中结构体只涉及数据结构，C++ 中类体现数据结构与算法的结合。C结构体中没有成员函数，可以被声明为变量、指针和数组等。类有成员函数 访问机制：结构体默认访问机制是public，而类默认是private 继承：class继承默认是private继承，struct继承默认是public继承 对象都具有的二方面特征的含义 静态特征：能描述对象的一些属性 动态特征：指对象表现出来的行为 成员函数通过什么来区分不同对象的成员数据？为什么能区分？ 通过this指针来区分，指向的是对象的首地址 构造函数与普通函数的形式不同 构造函数是特殊成员函数，一般用来初始化对象成员变量；构造函数的名字与类相同，不具有任何类型，不返回任何值； 构造函数的调用顺序： 先调用基类构造函数 按声明顺序初始化数据成员 最后调用自己的构造函数 抽象类的特点 指C++中憨纯虚函数的类，不能生成对象； 特点： 子类来实现接口类中没有实现的所有接口 接口方法前面右virtual关键词修饰，且等于0 只能被继承，不能独自生成对象（不能实例化） private 、protect、public三种限制访问类型的区别？ private:私有类型，只有本类的成员函数访问 peotect:保护型，本类和继承类可以访问 public:共有类型，任何类都可以访问 类外怎样访问类的非公有成员？ 友元、继承、公有成员函数 多重继承与多继承的区别 多继承指一个子类继承多个父类；对个数、继承方式无限制 多重继承指：当B类从A类派生，C类从B类派生。特点： 实例化子类时，会首先依次调用所有基类的构造函数，最后调用该子类的构造函数；销毁时相反 不论继承多少层，只要他们保持直接或间接的继承关系，子类都可以与其直接父类或间接父类构成is a的关系，且能通过父类的指针对直接子类或间接子类进行相应的才做，子类对象可以给直接父类或间接父类的对象或引用赋值或初始化 函数重载与虚函数区别： 函数重载同名函数完成不同功能，编译系统阶段通过函数参数个数、参数类型不同、函数返回值来区分调用哪一个函数。 虚函数是在基类中使用关键字virtural来声明一个函数为虚函数，是该函的功能在将来的派生类中定义或者在基类的基础上进行扩展，系统只能在运行阶段才能动态决定调用那一个函数，实现的是动态的多态性。 构造函数和析构函数是否可以被重载？ 构造函数可以被重载，析构函数不可以被重载；析构函数可以有多个且可以带参数，析构函数只能有一个且不带参数 拷贝构造函数调用情况： 通过使用另一个同类型的对象来初始化新创建的对象 如果函数的形参是类的对象，复制对象把它作为参数传递给函数 如果函数的返回值时类的对象，复制对象并从函数返回这个对象 深拷贝和浅拷贝的区别 在未定义显示拷贝构造函数时，系统会默认调用的拷贝函数（浅拷贝），能够完成成员的一一构造。数据成员没有指针类型时，浅拷贝是可行的；但有指针时，采用浅拷贝会使两个类的两个指针将指向同一个地址，当对象快结束时，会调用两次析构函数，导致指针悬挂现象。即必须使用深拷贝 深拷贝会在堆内存中另外申请空间来存储数据，避免指针悬挂现象 构造函数与析构函数的区别 构造函数的名称与类的名称相同，并不会返回任何类型，也不返回void，可以带参数 析构函数的名称与类的名称相同，只是在前面加~作为前缀，不返回任何值，也不带任何参数 目的不同：析构函数：主要用来在创建对象时初始化对象，即为对象成员变量赋初始值，总与new运算符一起使用在创建对象的语句中；析构函数：在跳出程序（关闭文件、释放内存等）前释放资源，清理善后工作 构造函数可以是虚函数吗？ 不可以。构造对象时，必须知道对象的实际类型。虚函数行为实在运行期间确定实际类型；虚函数的运行依赖于虚函数指针，虚函数真指针在构造函数中进程初始化，让他指向正确的许哈桉树虚函数表，而在对象构造期间，虚函数指针还未构造完成 ","link":"https://monsterju.github.io/post/mian-xiang-dui-xiang/"},{"title":"动态规划","content":"将一个规模大的问题转化为几个小的问题，通过解决小问题来得到整体的解。 其核心问题是问题的状态的定义与状态转移方程的求解。关键在于将重复出现的子问题在第一次求解之后就将其保存起来，以后再遇到时不用重复求解。是按照自底向上的方式计算 如题目求解的是最大/最小值，可行与否或者方案总数时考虑。 ##一般步骤： 将问题分解为不同的子问题，设计状态 定义状态转移方程，找出初始状态 执行状态转移，状态转移方程的求解 求出问题的最终答案 例子 贪吃蛇游戏 找出最长的递增子序列 nums = [1,5,2,4,3]的递增子序列有 [1,5],[1,2],[1,2,4],[1,2,3],[1,4][1,3],[2,4,[2,3] 暴力枚举 动态规划：记录重复的子序列，后续可减少搜索次数（记忆化搜索，带备忘录的递归、递归树的剪枝） 斐波那契数列 爬楼梯 ","link":"https://monsterju.github.io/post/dong-tai-gui-hua/"},{"title":"贪心算法","content":"Gready algorithm,在对问题求解时，总是做出在当前看来是最好的选择。也就是说，算法得到的是在某种意义上的局部最优解，不是对所有问题都能得到整体最优解。 一般步骤： 将复杂问题分解为多个子问题 子问题的解是当前所有解中的最优解 将所有子问题的解合并为原问题的解 疑问 当前子问题的解会不会对后续的状态产生影响/ 例子 哈夫曼树的构造：选取当前权值最小的两个结点组成二叉树 ","link":"https://monsterju.github.io/post/tan-xin-suan-fa/"},{"title":"EEGLab使用","content":"EEGlab下载安装 官网下载链接 将EEGLab的安装包解压 matlab路径设置 点击Matlab的Set Path—Add with Subfolders把EEGLAB文件夹添加进Matlab的搜索路径，并点击Save 保存。 安装ERPLAB插件 打开file -&gt; management extention -&gt; serach -&gt; 输入ERP，回车键搜索 脑电数据预处理 导入数据 Channel location 插入并设置FCz为参考电极 移除无用电极 重参考 滤波 插值坏导 降采样率 ICA 独立成分分析， 移除伪迹 脑电数据分析 ","link":"https://monsterju.github.io/post/eeglab-shi-yong/"},{"title":"用matlab处理眼电数据的一般步骤","content":"由Chat-gpt生成的第一次回答 一些通用的眼电数据处理步骤： 数据读取：使用Matlab中的工具（例如load函数）读取眼电数据文件，通常是以文本格式存储的。 数据预处理：包括去除基线漂移、滤波、去除噪声等操作。可以使用Matlab中的信号处理工具箱进行预处理，例如detrend函数去除基线漂移，filter函数进行滤波等。 眼动事件检测：通过寻找眼电数据中的特征（例如眼动振幅和速度），来检测眼动事件（例如注视和扫视）的发生。可以使用Matlab中的工具箱（例如Signal Processing Toolbox和Statistics and Machine Learning Toolbox）进行检测和分析。 数据分析：对检测到的眼动事件进行分析，例如注视点的位置、持续时间、次数等。可以使用Matlab中的统计工具箱（例如Statistics and Machine Learning Toolbox）进行分析和可视化。 绘制眼电数据 % 读取眼电数据 data = load('eye_data.txt'); % 注意修改文件名和路径 fs = 1000; % 数据采样率，根据实际情况修改 % 去除基线漂移 bl = mean(data); % 计算基线值 data = data - bl; % 去除基线漂移 % 滤波 fc = 30; % 滤波器截止频率，根据实际情况修改 [b, a] = butter(4, fc/(fs/2)); % 4阶巴特沃斯滤波器 data_filt = filtfilt(b, a, data); % 零相移滤波 % 绘制眼电数据 t = (1:length(data))/fs; % 时间轴 figure; subplot(2,1,1); plot(t, data); xlabel('Time (s)'); ylabel('Amplitude'); title('Raw eye data'); subplot(2,1,2); plot(t, data_filt); xlabel('Time (s)'); ylabel('Amplitude'); title('Filtered eye data'); 对眼电数据进行分类检测的一般步骤如下： 眨眼检测分类是一种常见的信号处理任务，可以通过 MATLAB 的信号处理工具箱和机器学习工具箱来实现。 以下是一些可能有用的步骤： 1. 采集眼电信号数据：通过连接到一个眼动仪或者其他相关设备来采集眼电信号数据。数据应该以数字形式存储，并包含一定数量的眨眼和非眨眼的信号样本。 2. 数据预处理：使用 MATLAB 的信号处理工具箱来对数据进行预处理，例如：滤波、去噪等。这可以提高后续分析的准确性和效率。 3. 特征提取：通过使用各种信号处理技术，例如：时域分析、频域分析、小波变换等，从眼电信号数据中提取特征。在特征提取过程中，应该考虑到眨眼和非眨眼信号之间的差异，以便能够更好地区分它们。 4. 特征选择：使用 MATLAB 的特征选择工具箱来选择最相关的特征，以便更好地分类眨眼和非眨眼信号。 5. 训练分类器：使用 MATLAB 的机器学习工具箱来训练分类器。有许多不同的分类器可以选择，例如：支持向量机、朴素贝叶斯、随机森林等。使用交叉验证等技术来确保分类器具有良好的泛化能力。 6. 测试分类器：使用测试集来测试分类器的性能。使用 MATLAB 的混淆矩阵等工具来评估分类器的性能，并进行必要的调整。 7. 应用分类器：将分类器应用于新的眼电信号数据，以实现眨眼检测分类。 %简单的MATLAB代码示例，用于对眼电数据进行分类检测，包括数据预处理、特征提取、特征选择和分类器训练等步骤： % Load eye-tracking data load('eye_data.mat'); % Data preprocessing % Remove artifacts caused by eye movements and blinks filtered_data = remove_artifacts(raw_data); % Feature extraction % Extract time-domain and frequency-domain features time_features = extract_time_features(filtered_data); freq_features = extract_freq_features(filtered_data); % Feature selection % Select the most representative and discriminative features selected_features = feature_selection(time_features, freq_features); % Classifier training % Train a support vector machine (SVM) classifier using the selected features svm_classifier = fitcsvm(selected_features, labels, 'KernelFunction', 'linear'); % Classifier testing % Test the classifier performance using a cross-validation approach cv = cvpartition(labels, 'kfold', 10); accuracy = zeros(cv.NumTestSets, 1); for i = 1:cv.NumTestSets train_features = selected_features(training(cv, i), :); train_labels = labels(training(cv, i)); test_features = selected_features(test(cv, i), :); test_labels = labels(test(cv, i)); svm_classifier = fitcsvm(train_features, train_labels, 'KernelFunction', 'linear'); predicted_labels = predict(svm_classifier, test_features); accuracy(i) = sum(predicted_labels == test_labels)/length(test_labels); end mean_accuracy = mean(accuracy); 眨眼分类 % Load eye blink data load('eyeblink_data.mat'); % Preprocess data filtered_data = bandpass(data, [1 30], fs); % bandpass filter between 1-30Hz normalized_data = normalize(filtered_data); % normalize data % Extract features window_size = round(fs*0.5); % 0.5 second window step_size = round(fs*0.1); % 0.1 second step features = extract_features(normalized_data, window_size, step_size); % Select features selected_features = feature_selection(features, labels); % Train classifier svm_model = fitcsvm(selected_features, labels, 'KernelFunction', 'linear'); % Test classifier test_data = normalized_data(1:round(end/2), :); % use first half of data for testing test_features = extract_features(test_data, window_size, step_size); test_features = test_features(:, selected_features); test_labels = labels(1:round(end/2)); predicted_labels = predict(svm_model, test_features); % Evaluate performance confusion_matrix = confusionmat(test_labels, predicted_labels); accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix(:)); precision = confusion_matrix(2,2)/(confusion_matrix(2,2) + confusion_matrix(1,2)); recall = confusion_matrix(2,2)/(confusion_matrix(2,2) + confusion_matrix(2,1)); f1_score = 2*precision*recall/(precision + recall); disp(['Accuracy: ' num2str(accuracy)]); disp(['Precision: ' num2str(precision)]); disp(['Recall: ' num2str(recall)]); disp(['F1 Score: ' num2str(f1_score)]); 该代码使用了一些自定义函数，例如 extract_features 和 feature_selection，这些函数可以根据你的具体需求进行编写。此外，该代码仅用于演示和启发作用，实际应用中可能需要进行更多的优化和调整。 ","link":"https://monsterju.github.io/post/yong-matlab-chu-li-yan-dian-shu-ju-de-yi-ban-bu-zou/"},{"title":"数字信号处理工具","content":"用Chat-gpt完成的回答：CCA、PCA、小波变换 CCA CCA指的是&quot;规范相关分析&quot;（Canonical Correlation Analysis），是一种统计学方法，用于探索两个多元变量集合之间的关系。它通过寻找两个变量集合之间的线性组合，使得它们的相关性最大化，从而发现它们之间的共同变化模式。 具体来说，CCA可用于寻找两个变量集合之间的线性相关性，这些变量集合可以是不同的，例如两个不同的生物数据集，或者是同一个数据集的不同特征集。它在多个领域都有应用，例如心理学、神经科学、计算机视觉等。 CCA的应用场景包括但不限于以下几个方面： 数据降维 特征提取 多模态数据融合 变量选择 数据探索与可视化 总之，CCA是一种强大的数据分析工具，可以揭示不同数据集之间的潜在联系和模式，从而提供更全面的数据分析和解释。 下面是使用CCA分析EOG数据的一般步骤： 收集眼电数据和其他感兴趣的生理信号数据（例如脑电图）。 对两个数据集进行预处理，例如去除基线漂移、降噪等操作。 对两个数据集进行时间戳对齐，以确保它们在同一时间点上。 将两个数据集分别进行主成分分析（PCA），以减少数据集的维度。 对两个数据集的主成分分别进行CCA分析，以找到它们之间的线性相关性。 对CCA结果进行解释和分析，以便理解两个数据集之间的关系。 PCA PCA是主成分分析（Principal Component Analysis）的缩写，是一种经典的多元统计方法，用于数据降维和特征提取。 PCA通过将数据映射到一个新的坐标系中，找到数据的主成分，从而减少数据集的维度。具体来说，它寻找最能解释数据变异性的主成分方向，并将数据投影到这些方向上，从而得到一个新的、较低维度的数据表示。 PCA可以用于以下几个方面： 数据降维：在高维数据中找到最主要的维度，将数据压缩为更低维度，使得数据更容易分析和可视化。 特征提取：在大量的特征中找到最能表征数据的特征，减少噪声和冗余信息，提高分类和聚类的准确性。 噪声过滤：通过对数据的主成分分析，识别和过滤掉噪声和异常值。 数据压缩：在不丢失重要信息的前提下，将数据压缩到更小的存储空间中，从而加快计算速度和节省存储资源。 总之，PCA是一种强大的数据处理和特征提取工具，可以帮助研究者更好地理解数据，提高数据分析和建模的准确性和效率。 小波变换 小波变换是一种信号分析技术，用于将信号分解为不同的频率成分，并提供有关每个成分在时间和频率上的信息。它是在20世纪80年代初由Mallat和Daubechies等人提出的，是时域和频域分析的一种有力补充。 与傅里叶变换不同，小波变换不是在整个时间域上分析信号的，而是通过分解信号成多个小波包（即小波分解），来分析不同尺度和频率范围内的信号。小波分解可以看作是将信号从时间域转换到小波域的过程。 小波变换具有多尺度分析的优点，可以逐层分解信号，提取出高频和低频成分，并对每一层的小波系数进行处理和分析，从而得到更加详细的频率和时间信息。此外，小波变换还可以对信号进行去噪、压缩和特征提取等应用。 常见的小波变换包括离散小波变换（DWT）和连续小波变换（CWT）。离散小波变换适用于离散的、有限长的信号，而连续小波变换适用于连续的、无限长的信号。在实际应用中，通常采用小波变换的离散形式，即DWT。 小波变换已广泛应用于信号处理、图像处理、模式识别、语音处理、金融分析等领域。 ","link":"https://monsterju.github.io/post/shu-zi-xin-hao-chu-li-gong-ju/"},{"title":"KMP算法思考","content":"字符串匹配问题：&quot;字符串A是否为字符串B的子串?如果是的话出现在B的哪些位置?&quot; 字符串A称为模式串，字符串B称为主串（模式）。 Brute-Force算法： 假设n为主串长度，m为模式串长度。每一轮字符串比较：最差的情况为模式串最后一个字与主串不同其他都相同（如模式串为AAB，主串对应部分为AAC），必须走完整个字符串才能得出结果，因此复杂度为O(m)。所有轮字符串比较：最差的情况是移动到最后一次比较才寻找得到，总共需要n-m+1次，主串通常比模式串长很多，故Brute-Force时间复杂度为O(nm)。 暴力匹配中，每一趟失败都是从模式后移一位再从头开始匹配，此尽可能减少比较的趟数是算法优化的方向，也是KMP算法的核心思想：每次匹配过程中推断出后续完全不可能匹配成功的匹配过程，从而减少比较的趟数。 ###利用模式串存在的规律，对BF的优化 思路一 通过求字符串的前缀和后缀与部分匹配值求模式串的next数组 前缀：除最后一个字符外，字符串的所有头部子串 后缀：除第一个字符外，字符串的所有尾部子串 部分匹配值(Partial Match,PM)：字符串的前缀和后缀的最长相等前后缀长度 移动位数 = 已匹配的字符数-对应的部分匹配值（最后一个匹配字符的对应部分匹配值） More = (j -1) - PM[j-1]，j为移动指针 原理：减少匹配趟数需要排除不可能匹配成功的过程。每一趟模式匹配中，都是将模式串与主串比较，模式串为关键，每一次匹配都是对模式串每个字符的比较，匹配失败为有一个字符不同，但可能有部分匹配成功，若模式串存在特殊规律，在部分匹配成功的字符串中可能存在与模式串前缀相同的后缀字符串，或与前缀不同的部分即完全不可能匹配的后缀字符串，移动即不进行匹配与前缀不同的字符，不需要对主串进行逐一后移比较，可减少匹配趟数在已匹配的字符串中找到从最后开始的出现的最长相等前后缀的字符子串，从该字符串开始，移动的位数就是已匹配的字符数-该字符子串的长度（即PM值） next数组为PM表右移一位： 第一个元素右移后用-1表示，因为若是第一个元素就匹配失败，则需将子串向右移一位，不需要计算计算子串移动的位数 最后一个元素在右移过程中溢出，部分匹配值为在已匹配的字符使用，若最后一个元素匹配，则模式匹配完成，故可以舍去 思路二 利用状态机的思考KMP ","link":"https://monsterju.github.io/post/kmp-suan-fa-si-kao/"},{"title":"DS提问","content":"简单摘抄的概念 基础 数据、数据元素、数据项、数据结构 数据的逻辑结构和存储结构 逻辑：集合、线性结构、树形结构、图状结构（网状结构） 存储：顺序存储、链式存储、索引存储、散列存储 算法特性和算法设计要求 有穷性、确定性、输入、输出、可行性 正确性、可读性、健壮性、高效率与低存储量需求 时间复杂度和空间复杂度 常见排序算法的时间复杂度 队列假溢出：存储区未满但溢出 循环队列：空一个位置，区分队空队满；逻辑环，顺序存储 队空：front = rear 队满：front = (rear+1)%maxsize 插入删除：（front/rear+1)maxsize 设标记tag记录最后一次操作是插入还是删除，判断front = rear 属于那种情况，后再平移操作 增设记录队列长度的变量，再平移操作 静态链表 用数组来描述线性表的链式结构，指针是结点的相对下标（数组下标） 预先分配连续的内存空间 头指针、首元结点与头结点的区别 存储的第一个元素之前是否附设一个结点 头结点优点：使对首元结点的操作与其他结点操作一致；头指针非空，使空表和非空表的操作一致 顺序表和链表的比较 存取（读写）方式：是否随机存取 逻辑结构与存储结构：逻辑上相邻，存储上是否相邻 查找、插入与删除操作： 按值查找，区分是否有序，O(n)与O(logn),可用折半查找；按序号查找，O(1)与O(n) 插入删除，平均移动半个表长的元素与修改指针域 空间分配：静态动态分配 快速排序优点 prim（普利姆）算法和kruskal（克鲁斯卡尔）算法的区别 KMP算法: 概念 有限状态机 实现单链表的就地逆置 就地指算法的辅助空间为O(1) 对于有头结点L的链表：另设两个指针p、q分别指向第一个元素与第二个元素，首先L指向NULL，遍历链表中执行：p-&gt;next = L, L= p, p = q, q = q-&gt;next 二叉排序树的概念与算法 左子树上所有结点的值均小于根结点的值 右子树上所有结点的值均大于根结点的值 左右子树也是二叉排序树 递归查找 平衡二叉树：任意结点的不超过1 平衡因子：左右子树高度差 对二叉树二改进，可减少查找次数 旋转调整 哈夫曼树：带权路径长度最小的二叉树（n个权值就有n个叶结点） 构造规则： 将w1、w2、... 、wn看成是有n棵树的森林，每棵树只有一个结点 在森林中选出两个根结点的权值最小的树合并为一棵新树的左右子树，新树的根结点权值为其左右子树根结点结点权值之和 从森林中删除这两棵树，并将新树加入森林 重复上述两步，直至森林中只剩一棵树为止，该树即为所求的哈夫曼树 特点：权值越大的结点，离根结点越近；树中没有度为1的结点； 哈夫曼编码：最短前缀编码 带权路径长度：Σ（叶结点权值*路径长度） 16. 深度优先搜索遍历和广度优先搜索遍历的过程 深度：一条路走到头，撞墙回头，贪。栈。类似树的先序遍历 广度：稳扎稳打，逐步扩散。队列。类似树的层次遍历 深度、广度遍历不一定唯一（可从不同顶点开始） 贪吃蛇游戏思考：每次吃奖励，是通过一条路直冲，直达奖励，还是通过盘曲身体，慢慢靠近奖励 最小生成树的理解 连通图的最小连通子图，在添加一条边就成一个环 普里姆算法 库鲁斯卡尔算法 n个结点的最小生成树有n个结点，n-1条边 二叉树的存储方式 顺序结构：用数组来存储二叉树，按编号依次填入数组；占用完全二叉树的存储空间，可能浪费空间 链式存储：双亲、兄弟等 大根堆与小根堆 堆，一种数据结构，可看作完全二叉树 任何一个非叶结点的值都不大于(或不小于)其左右结点的值 堆排序 非连通图如何访问每一个结点 从每一个连通分量中选择初始点，分别进行遍历 DFS或者BFS M阶B树和M阶B+ 树的区别 二叉树的遍历 先序、中序、后序、层次遍历 装填因子 = 填入表中的元素个数/ 散列表的长度 散列表长度不是求余值 栈和队列的应用 受限的线性表 队列，先进先出，图的BFS、二叉树的层次遍历、缓存区 栈，后进后出，括号匹配、递归调用、表达式后缀中缀计算 排序方法 - 插入类：直接插入排序、希尔排序 - 交换类：冒泡排序、快速排序 - 选择类：简单选择排序、堆排序 - 归并类：二路归并排序 - 基数排序 不稳定排序：简希快堆；简单选择、希尔、快速、堆 内部排序与外部排序 区别：排序期间元素是否全部放入内存中进行排序； 内外存之间进行移动需要缓冲区 AOE网：带权有向图中，以顶点表示事件，边表示活动，边上的权值表示完成该活动的开销 - 关键路径及关键活动，总开销受关键路径（活动）的影响，开销改变是不是关键活动，有多少条关键活动，是否有部分重合 ","link":"https://monsterju.github.io/post/ds-ti-wen/"},{"title":"决策树","content":"概念 (decision tree)，是一种基本的分类与回归方法。分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示一个类。 把决策树看成一个if-then规则的集合，将决策树转换成if-then规则的过程是这样的：由决策树的根结点(root node)到叶结点(leaf node)的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的if-then规则集合具有一个重要的性质：互斥并且完备。这就是说，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。 ##准备工作 特征选择 选择标准：信息增益（information gain）或信息增益比 （香农）熵：信息期望值 所有类别所有可能值包含的信息期望值（数学期望）： 经验熵：概率由数据估计（最大拟然估计）得到 条件熵 决策树生成和修改 数据集构造决策树算法所需要的子功能模块，包括经验熵的计算和最优特征的选择。其工作原理如下：得到原始数据集，然后基于最好的属性值划分数据集，由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分。第一次划分之后，数据集被向下传递到树的分支的下一个结点。在这个结点上，我们可以再次划分数据。因此我们可以采用递归的原则处理数据集。 构建决策树的算法有很多，比如C4.5、ID3和CART，这些算法在运行时并不总是在每次划分数据分组时都会消耗特征。由于特征数目并不是每次划分数据分组时都减少，因此这些算法在实际使用时可能引起一定的问题 ","link":"https://monsterju.github.io/post/jue-ce-shu/"},{"title":"k-近邻算法","content":"原理 （k-nearest neighbor)，是一个基本分类与回归方法。存在一个样本数据集合，也称作为训练样本集，并且样本集中每个数据都存在标签，即我们知输道样本集中每一个数据与所属分类的对应关系。入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似数据(最近邻)的分类标签。 特征以距离度量（欧式距离）： k-近邻算法步骤如下： 1.计算已知类别数据集中的点与当前点之间的距离； 2.按照距离递增次序排序； 3.选取与当前点距离最小的k个点； 4.确定前k个点所在类别的出现频率； 5.返回前k个点所出现频率最高的类别作为当前点的预测分类。 流程： 数据解析：将待处理数据的格式改变为分类器可以接收的格式（特征矩阵和对应的分类标签向量） 数据可视化 数据归一化：特征值属性对计算结果的影响不同，可进行权重分配。 数值归一化：newValue = (oldValue - min) / (max - min)，其中min和max分别是数据集中的最小特征值和最大特征值。 测试算法(验证分类器) 优点 简单好用，容易理解，精度高，理论成熟，既可以用来做分类也可以用来做回归；无需参数估计，无须训练； 可用于数值型数据和离散型数据； 训练时间复杂度为O(n)；无数据输入假定； 对异常值不敏感，对噪声不敏感 缺点 计算复杂性高；空间复杂性高； 样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）； 一般数值很大的时候不用这个，计算量太大。但是单个样本又不能太少，否则容易发生误分。计算每一个待分类样本要与全体已知样本计算距离，才能得到k个最近邻点； 最大的缺点是无法给出数据的内在含义。(可解释性差) 算法改进 消除维数灾难（出现不相关或相关性低的的属性，欧式距离会不准确，消耗大量计算资源：消除不相关属性即特征选择；属性加权。 快速KNN算法：将样本进行排序，在所有有序的样本队列中搜索k个最邻近样本，从而减少搜索时间/ ","link":"https://monsterju.github.io/post/knn/"},{"title":"C语言提问","content":"常见问题 C与C++ 的区别 C是面向过程，C++是面向对象的 面向过程编程：分析解决问题的步骤，并按步骤实现，人直接调用函数。性能好。 面向对象编程：把问题分解成各个对象，为了描述某个事物在整个解决问题的步骤中的行为。易维护、易复用及易拓展，有封装、继承及多态特性。类的调用需实例化，开销大。 C语言程序的三种基本结构：顺序，选择，循环 gcc编译过程：Linux编译器，过程包括： 预处理：头文件包含、宏替换、条件编译、删除注释 编译： 进行词法、语法、语义分析，编译成汇编文件（.obj文件） 汇编：将汇编文件转化为二进制文件 （.o文件） 链接：将各个二进制文件+所需的库+启动代码链接成可执行文件（.exe) 传值、传址、引用的区别： 是否为形参分配地址（传值、传址会） 形参值的改变是否影响实参的值（传值、传址会） 传址与引用：注意对贴标签的理解；引用&lt;别名，对形参和实参名字的操作影响一致&gt;,传址&lt;调用指针，改变指针值时影响不同&gt; 局部变量使用 ** static **定义的作用 函数调用结束后，保留原值（储存单元不释放）:从栈中存放改为静态存储区存放 注意作用域： struct和class的区别： C：struct只能定义成员变量，不能定义成员函数 C++：struct可以有构造函数与成员函数，且有class的其他特性 C++中struct默认成员为public,class中成员为private break和continue的区别： continue只结束本次循环，而不是终止整个循环 continue只能在循环语句中使用，即switch不可使用 &amp;&amp; 和 &amp;，|| 和 | 的区别 逻辑运算和求值运算 typedef 和 #define的区别： 类型定义关键字和预处理指令：编译阶段和预处理阶段（是否涉及类型检测） typedef为已有数据类型取别名 宏定义是字符替换，没有数据类型的区别，不分配内存，不会进行类型检查，可能产生边际效益等错误 指针和数组的区别 指针保存数据的地址，数组保存数据，数组名代表数组首元素的地址 指针间接访问数据，数组直接访问数据 指针通常动态数据结构，数组通常用于存储固定数据个数且数据元素相同 运算符优先级关系： ！&gt; 算术运算符 &gt; 关系运算符 &gt; &amp;&amp; &gt; || &gt; 赋值运算符 内存分配和内存释放： 静态存储类型：系统自动分配、释放 动态存储类型：在程序实际运行过程中，按需求分配，系统不会自动释放（free函数） 内存分布： 栈区：编译器自动分配释放，存放函数的局部变量 堆区：程序员分配和释放，动态分配（分配方式类似链表，不是DS的堆） 全局静态区：存放全局变量和常量 文字常量区：存放常量字符串 代码区：存放函数体的二进制代码 *p++ 和（*p)++ 区别： *p++ ：取当前值，再移动地址 （*p)++ 区别：取当前值，数值加1 #include&lt;file.h&gt; 和 #include &quot;file.h&quot; 思维区别: 首先从编译器默认的include目录寻找头文件/在源码当前目录下寻找头文件 局部变量和全局变量重名： 使用全局变量会使用“::” 作用域，局部屏蔽全局 内联函数: 修饰符inline 直接复制内联函数代码到主函数代码中，不跳转到内联函数的入口地址（不同于函数调用），顺序执行，可能被复制数份放在对应位置 变量命名规则:有字母、数字及下划线组成，不能以数字开头 函数定义和函数声明的区别： 声明不包括函数体 对函数功能的确立：指定函数名、函数类型、形参及其类型、函数体等 野指针：未初始化的指针，指向一个随意的地址。 指针变量声明时未被初始化：可以是具体地址值，或NULL 指针p被free或delete之后，没有设置为NULL 指针操作超越了变量的作用范围：在变量的作用域结束前释放掉变量的地址空间并让指针指向NULL 库函数：写好的、成熟的、可复用的代码。底层库 结构体内存对齐： 数据成员对齐,第一个成员放在offset为0的地方，以后每个成员存储的起始位置要从自身成员大小的整数倍开始 结构体作为成员：嵌套，从结构体内部最大元素大小的整数倍地址开始 结构体的总大小必须是内部最大成员的整数倍 const char*p , char * const p 的区别 常量指针：const位于的左边，const就是用来修饰指针所指向的变量，即指针指向为常量，指针所指对象的值 p 不能更改，但指针p可以修改； 指针常量：const位于的右边，const 修饰指针本身，即指针本身是常量。p表示一个指针地址，指针变量不能被修改，但指针所指向的值p可以被修改。 ","link":"https://monsterju.github.io/post/c-yu-yan/"},{"title":"Markdown语法练习","content":" 标题 一级标题 markdown 二级标题 markdown😀 六级标题 markdown 自定义标题 markdown {#head1} 段落 : aaaaaa aaaaa aaaaaaaaa oo 1.sssss 字体加粗** markdown 按揭首付年岁地方VS v尼斯哦对分散的v你i送点击发送大 附件宋代四大佛山方法士大夫士大夫撒旦是 printf(&quot; &quot;); printf(&quot; &quot;); aaaa 66666 [first blog] (./first blog &quot;点击跳转到标题页&quot;) aaaaaaaaaaa ","link":"https://monsterju.github.io/post/markdown-yu-fa-lian-xi/"},{"title":"first blog","content":"hello world! ","link":"https://monsterju.github.io/post/first-blog/"}]}